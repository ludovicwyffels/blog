{"componentChunkName":"component---src-templates-tags-tsx","path":"/tags/docker/","webpackCompilationHash":"28b74a5dec589e4586df","result":{"data":{"allTagYaml":{"edges":[{"node":{"id":"Angular","description":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"Architecture","description":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"AWS","description":"Amazon Web Services is a subsidiary of Amazon that provides on-demand cloud computing platforms to individuals, companies and governments, on a paid subscription basis. The technology allows subscribers to have at their disposal a virtual cluster of computers, available all the time, through the Internet.","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"Best","description":"Collection of in-deep guides about software development","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"CSS","description":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"DevOps","description":"Set of practices that automates the processes between software development and IT teams, in order that they can build, test, and release software faster and more reliably.","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"Git","description":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"Google Cloud","description":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"Javascript","description":"The most used language in the world","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"Kindle","description":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"Node.js","description":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"React","description":"The most powerful UI library ever","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"Self","description":"Thoughs about life.","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}},{"node":{"id":"SQL","description":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcZUED//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAWEAADAAAAAAAAAAAAAAAAAAAAASD/2gAIAQEAAT8hHP8A/9oADAMBAAIAAwAAABD47//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABgQAAMBAQAAAAAAAAAAAAAAAAABERAh/9oACAEBAAE/EKPlG+FP/9k=","aspectRatio":1.4992503748125936,"src":"/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg","srcSet":"/static/9fb9647467dab072b9ebe36e9e52ae95/f8f18/blog-cover.jpg 930w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/0e6ff/blog-cover.jpg 1860w,\n/static/9fb9647467dab072b9ebe36e9e52ae95/883ab/blog-cover.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}}}}]},"allMarkdownRemark":{"totalCount":2,"edges":[{"node":{"excerpt":"J’ai installé Docker Swarm et Kubernetes sur deux machines virtuelles. J’ai trouvé que Docker Swarm est très facile à installer et à configurer, alors que Kubernetes est un peu plus difficile à installer mais reste simple à utiliser. Introduction Cela fait des années que je veux essayer des conteneurs: la configuration manuelle de serveurs prend du temps, n’est pas reproductible et risque d’introduire des différences entre mon environnement de test local et la production. Les containers offrent une solution à tous ces problèmes et facilite beaucoup l’exécution d’instances supplémentaires d’une application. Cela peut rendre un service plus évolutif. Pour exécuter un service évolutif, vous avez besoin d’un moteur Container Orchestration qui répartit la charge en exécutant des conteneurs sur plusieurs ordinateurs et en envoyant des demandes à chaque instance de l’application. Docker Swarm et Kubernetes sont deux moteurs d’orchestration populaires. J’ai décidé d’essayer les deux en déployant la même application avec chaque moteur. Création du conteneur J’ai décidé d’utiliser Samba pour l’application de test. Samba est un serveur de fichiers populaire permettant aux ordinateurs Linux de partager des fichiers avec des ordinateurs Windows. Il communique via TCP sur le port 445. C’est la première fois que je travaille avec Docker, j’ai donc modifié un conteneur Samba standard afin d’inclure le fichier que je voulais servir. Après le tutoriel de Docker, j’ai lancé manuellement le conteneur à partir de la ligne de commande pour vérifier son fonctionnement: Et en effet, j’ai pu me connecter au serveur Samba dans le conteneur avec smbclient Maintenant que je sais que le conteneur fonctionne, je peux l’utiliser dans un moteur d’orchestration de conteneur. Préparer les machines virtuelles J’ai créé deux machines virtuelles exécutant Ubuntu 18.04 dans VirtualBox. J’ai ajouté une carte réseau supplémentaire à chaque machine virtuelle, configurée pour le réseau interne afin qu’ils puissent se parler: https://cdn-images-1.medium.com/max/1600/1*chCjRdcU_mV9ioAyQ7oB5A.png Ensuite, j’ai ajouté un serveur DHCP pour attribuer des adresses IP à chaque machine virtuelle: Les machines virtuelles peuvent désormais communiquer entre elles. Cela donne à ma machine virtuelle principale l’adresse IP 10.133.7.100. Docker Swarm Docker Swarm est un moteur d’orchestration de conteneur intégré à Docker lui-même. Quand je l’ai trouvé, j’étais sceptique: pourquoi l’utiliser à la place des Kubernetes, beaucoup plus célèbres? La réponse: Docker Swarm est axé sur la simplicité par rapport à la configuration. Cela ressemblait à l’iOS des moteurs d’orchestration de conteneurs par rapport à l’Android de Kubernetes. Mise en place de Docker Swarm Docker Swarm est facile à installer: il suffit d’installer Docker et docker-compose. Ensuite, après le tutoriel officiel, j’ai exécuté la seule commande nécessaire pour démarrer le noeud du gestionnaire, en transmettant l’adresse IP de la machine virtuelle actuelle: C’est tout: le moteur Docker tourne maintenant en mode Swarm. Ensuite, j’ai déployé un registre privé Docker afin que les autres noeuds puissent extraire des images, en suivant à nouveau les instructions d’installation: Déploiement de l’application Docker Swarm utilise le format Docker Compose pour spécifier les conteneurs à exécuter et les ports qu’ils exportent. Après le didacticiel Docker Compose, j’ai créé ce manifeste Docker Compose: Cela indique à Docker Compose de créer le fichier Docker à partir du répertoire «sambaonly», d’upload/pull les conteneurs construits vers mon registre privé nouvellement configuré et d’exporter le port 445 à partir du conteneur. Pour déployer ce manifeste, j’ai suivi le tutoriel de Docker Swarm. J’ai d’abord utilisé Docker Compose pour créer et télécharger le conteneur dans le registre privé: Une fois le conteneur créé, l’application peut être déployée avec la commande docker stack deploy, en spécifiant le nom du service: Et maintenant, l’application fonctionne sous Samba Swarm. J’ai testé qu’il fonctionne toujours avec smbclient: Ajout d’un autre noeud Ici encore, la simplicité de Docker Swarm transparaît. Pour installer un deuxième noeud, j’ai d’abord installé Docker, puis exécuté la commande que Docker m’avait donnée lors de l’installation de swarm: Pour exécuter mon application sur les deux nœuds, j’ai exécuté la commande scale de Docker Swarm sur le nœud du gestionnaire: Sur le nouveau noeud de travail, le nouveau conteneur est apparu: Test de l’équilibrage de charge (load balancing) Docker Swarm comprend un load balancing intégré appelé routeur Mesh: les demandes adressées à l’adresse IP de tout noeud sont automatiquement réparties sur l’ensemble de Swarm. Pour tester cela, j’ai établi 1000 connexions à l’adresse IP du noeud du gestionnaire avec nc: Samba génère un nouveau processus pour chaque connexion. Par conséquent, si l’équilibrage de la charge fonctionne, je m’attendrais à environ 500 processus Samba sur chaque noeud de Swarm. C’est bien ce qui se passe. Après avoir exécuté le script pour établir 1000 connexions, j’ai vérifié le nombre de processus Samba sur le gestionnaire (10.133.7.100): Et sur le noeud travailleur (10.133.7.50): Ainsi, exactement la moitié des demandes adressées au noeud de gestion ont été redirigées de manière magique vers le premier noeud de travail, ce qui montre que le cluster Swarm fonctionne correctement. J’ai trouvé que Docker Swarm était très facile à installer et il fonctionnait bien sous une charge (légère). Kubernetes Kubernetes est en train de devenir l’industrie standard de l’orchestration de conteneurs. C’est beaucoup plus flexible que Docker Swarm, mais cela rend plus difficile la configuration. Je l’ai trouvé pas si difficile, cependant. Pour cette expérience, au lieu d’utiliser un environnement de développement Kubernetes pré-construit tel que minikube, j’ai décidé de configurer mon propre cluster, à l’aide de Kubadm, WeaveNet et MetalLB. Mise en place de Kubernetes Kubernetes à la réputation d’être difficile à configurer: vous avez entendu le processus complexe en plusieurs étapes du didacticiel Kubernetes the Hard Way Les développeurs de Kubernetes ont simplifié l’utilisation de kubeadm. Malheureusement, Kubernetes étant si flexible, le tutoriel sur kubeadm ne couvre pas encore quelques étapes. J’ai donc dû déterminer le réseau et l’équilibreur de charge à utiliser moi-même. Voici ce que j’ai fini par lancer. J’ai d’abord dû désactiver Swap sur chaque noeud: Ensuite, j’ai configuré le noeud maître (10.133.7.100) avec la commande suivante: L’option --pod-network-cidr attribue une adresse réseau interne à tous les noeuds du réseau, utilisée pour les communications internes dans Kubernetes. Les options --apiserver-advertise-address et --apiserver-cert-extra-sans ont été ajoutées à cause d’un problème particulier dans l’installation de VirtualBox: la carte virtuelle principale des machines virtuelles (IP 10.0.2.15) ne peut accéder qu’à l’Internet. J’ai dû préciser que d’autres noeuds doivent accéder au maître à l’aide de l’adresse IP 10.133.7.100. Après avoir exécuté cette commande, Kubeadm a affiché quelques instructions: J’ai raté ces instructions la première fois et je n’ai donc pas terminé la configuration. J’ai ensuite passé une semaine entière à me demander pourquoi aucun de mes conteneurs ne fonctionnait! Après avoir enfin lu les instructions, je devais faire trois autres choses: Tout d’abord, je devais exécuter les commandes données par kubeadm pour configurer un fichier de configuration. Par défaut, Kubernetes ne planifie pas les conteneurs sur le nœud maître, mais uniquement sur les noeuds de travail. Comme je n’ai qu’un seul noeud pour le moment, le tutoriel m’a montré cette commande pour autoriser l’exécution de conteneurs sur le seul noeud: Enfin, je devais choisir un réseau pour mon cluster. Installation du réseau Contrairement à Docker Swarm, qui doit utiliser sa propre couche de routage maillé pour la mise en réseau et l’équilibrage de la charge, Kubernetes offre de multiples choix pour la mise en réseau et l’équilibrage de la charge. Le composant de mise en réseau permet aux conteneurs de communiquer en interne. J’ai fait des recherches et cet article comparatif suggérait Flannel ou WeaveNet, car ils sont faciles à configurer. Ainsi, j’ai décidé d’essayer WeaveNet. J’ai suivi les instructions du didacticiel kubeadm pour appliquer la configuration de WeaveNet: Ensuite, pour permettre aux conteneurs de communiquer avec le monde extérieur, j’ai besoin d’un équilibreur de charge. D’après mes recherches, j’ai eu l’impression que la plupart des implémentations de l’équilibreur de charge Kubernetes se concentrent uniquement sur les services HTTP, et non sur le TCP brut. Heureusement, j’ai trouvé MetalLB, un projet récent (vieux d’un an) qui comble cette lacune. Pour installer MetalLB, j’ai suivi son didacticiel de mise en route et j’ai tout d’abord déployé MetalLB: Ensuite, j’ai attribué la plage d’adresses IP 10.133.7.200 à 10.133.7.230 à MetalLB, en créant et en appliquant ce fichier de configuration: Déploiement de l’application Les fichiers de configuration du service de Kubernetes sont plus détaillés que ceux de Docker Swarm, en raison de la flexibilité de Kubernetes. En plus de spécifier le conteneur à exécuter, comme Docker Swarm, je dois spécifier comment chaque port doit être traité. Après avoir lu le tutoriel de Kubernetes, j’ai proposé cette configuration de Kubernetes, composée d’un service et d’un déploiement. https://gist.github.com/ludovicwyffels/911bb25b611f3519745aeee0d53c6447 Ce service demande à Kubernetes d’exporter le port TCP 445 de nos conteneurs Samba vers l’équilibreur de charge. https://gist.github.com/ludovicwyffels/41022da159c539e45027c68776f459d8 Cet objet Deployment indique à Kubernetes d’exécuter mon conteneur et d’exporter un port que le service doit gérer. Notez le replicas: 1 - c’est le nombre d’instances du conteneur que je veux exécuter. Je peux déployer ce service sur Kubernetes en utilisant kubectl apply: Et, après avoir redémarré ma machine virtuelle à quelque reprises, le déploiement a finalement commencé à fonctionner: Mon service est maintenant disponible sur l’adresse IP externe attribuée par MetalLB: Ajout d’un autre noeud Ajouter un autre noeud dans un cluster Kubernetes est beaucoup plus simple: il me suffisait d’exécuter la commande donnée par kubeadm sur le nouvel ordinateur: Bizarreries de ma configuration J’ai dû faire deux changements en raison de la configuration de VirtualBox: Premièrement, comme ma machine virtuelle dispose de deux cartes réseau, je dois indiquer manuellement l’adresse IP de ma machine à Kubernetes. Selon ce problème, je devais éditer Et changer une ligne en avant de redémarrer Kubernetes: L’autre solution concerne le registre Docker: comme le nouveau noeud ne peut accéder à mon registre privé sur le noeud maître, j’ai décidé de procéder à un terrible hack et de partager le registre de mon noeud maître vers la nouvelle machine à l’aide de ssh: Cela transmet le port 5000 du noeud principal, dora (qui exécute le registre Docker) à localhost, où Kubernetes peut le trouver sur cette machine. En production réelle, il est probable que le registre Docker sera hébergé sur une machine distincte, afin que tous les noeuds puissent y accéder. “Scaling” de l’application Lors de la deuxième installation de l’ordinateur, j’ai modifié mon déploiement d’origine pour ajouter une autre instance de l’application: Après avoir redémarré le maître et le worker à quelques reprises, la nouvelle instance de mon application a finalement quitté le statut de CreatingContainer et a commencé à s’exécuter: Test de l’équilibrage de charge J’ai utilisé la même procédure pour ouvrir 1000 connexions à Samba s’exécutant sur Kubernetes. Le résultat est intéressant. Master: Worker: Kubernetes / MetalLB a également équilibré la charge sur les deux machines, mais la machine principale a eu un peu moins de connexions que le worker. Je me demande pourquoi. Quoi qu’il en soit, cela montre que j’ai finalement réussi à installer Kubernetes après plusieurs détours. Comparaison et conclusion Fonctionnalités communes aux deux: les deux peuvent gérer des conteneurs et gérer intelligemment les demandes d’équilibrage de charge sur la même application TCP sur deux machines virtuelles différentes. Les deux ont une bonne documentation pour la configuration initiale. Les atouts de Docker Swarm: une configuration simple, aucune configuration requise, une intégration étroite avec Docker. Les points forts de Kubernetes: composants souples, nombreuses ressources disponibles et add-ons. Kubernetes vs Docker Swarm est un compromis entre simplicité et flexibilité. J’ai trouvé plus facile d’installer Docker Swarm, mais je ne peux pas, par exemple, échanger l’équilibreur de charge contre un autre composant. Il n’ya aucun moyen de le configurer: je devrais tout désactiver en même temps. Sur Kubernetes, il m’a fallu un certain temps pour trouver la bonne configuration, mais en échange, je pouvais changer certaines parties de mon cluster selon les besoins et installer facilement des add-ons, tels qu’un tableau de bord sophistiqué. Si vous voulez juste essayer Kubernetes sans toute cette configuration, je vous suggère d’utiliser minikube, qui offre une machine virtuelle de cluster Kubernetes prédéfinie, aucune installation requise. Enfin, je suis impressionné par le fait que les deux moteurs ont pris en charge les services TCP bruts: d’autres fournisseurs de services d’infrastructure en tant que services, tels que Heroku ou Glitch, ne prennent en charge que l’hébergement de sites Web HTTP. La disponibilité des services TCP signifie que l’on peut déployer ses propres serveurs de base de données, ses serveurs de cache et même ses serveurs Minecraft en utilisant les mêmes outils pour déployer des applications Web, faisant de la gestion de l’orchestration de conteneurs une compétence très utile. En conclusion, si je construisais un cluster, j’utiliserais Docker Swarm. Si je payais quelqu’un d’autre pour construire un cluster pour moi, je demanderais Kubernetes. Ce que j’ai appris Comment travailler avec les conteneurs Docker Comment configurer un cluster Docker Swarm à deux noeuds Comment configurer un cluster Kubernetes à deux noeuds et quels choix fonctionneraient pour une application basée sur TCP Comment déployer une application sur Docker Swarm et Kubernetes Comment réparer quoi que ce soit en redémarrant un ordinateur assez souvent, comme si je utilisais encore Windows 98 Kubernetes et Docker Swarm ne sont pas aussi intimidants qu’ils semblent","timeToRead":16,"frontmatter":{"title":"Docker Swarm vs Kubernetes","subtitle":"J'ai trouvé que Docker Swarm est très facile à installer et à configurer, alors que Kubernetes est un peu plus difficile à installer mais reste simple à utiliser.","tags":["Kubernetes","Docker","DevOps"],"date":"2018-11-01T08:00:00.000Z","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQDBf/EABYBAQEBAAAAAAAAAAAAAAAAAAIAAf/aAAwDAQACEAMQAAAB6OtBGFa2/8QAGhABAAIDAQAAAAAAAAAAAAAAAQACAxESE//aAAgBAQABBQJyW7vkSe1iaNoIBU//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEQH/2gAIAQMBAT8Bia//xAAZEQABBQAAAAAAAAAAAAAAAAAAAQIRElH/2gAIAQIBAT8BlCzcP//EABoQAAMBAAMAAAAAAAAAAAAAAAABESESMUH/2gAIAQEABj8CU6MU30k5FhGRKH//xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhQTFRYf/aAAgBAQABPyHjwtkhQI2lwNVg2E1C5WkTplYQ8n//2gAMAwEAAgADAAAAEAjv/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQAhYf/aAAgBAwEBPxAQO3S//8QAFxEBAQEBAAAAAAAAAAAAAAAAAQARIf/aAAgBAgEBPxDsOTD/xAAaEAEBAQADAQAAAAAAAAAAAAABEQAhMUFx/9oACAEBAAE/EEhJlEVOtxTFYSS051ExT5vZ7lQoemZMl9hTc8RsE3//2Q==","aspectRatio":1.7772511848341233,"src":"/static/6dc1a1b98e66073dbd7e7471a7fff24c/9f583/dockerswarm-vs-kubernetes.jpg","srcSet":"/static/6dc1a1b98e66073dbd7e7471a7fff24c/68709/dockerswarm-vs-kubernetes.jpg 310w,\n/static/6dc1a1b98e66073dbd7e7471a7fff24c/53593/dockerswarm-vs-kubernetes.jpg 620w,\n/static/6dc1a1b98e66073dbd7e7471a7fff24c/9f583/dockerswarm-vs-kubernetes.jpg 750w","sizes":"(max-width: 750px) 100vw, 750px"}}},"author":{"id":"ludo","bio":"Développeur senior. Fullstack + DevOps","avatar":{"children":[{"__typename":"ImageSharp","fixed":{"src":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png"}}]}}},"fields":{"layout":"post","slug":"/dockerSwarm-vs-kubernetes/"}}},{"node":{"excerpt":"Les conteneurs d’applications ont émergé comme un outil puissant dans le développement de logiciels modernes. Plus légers et plus économes en ressources que les machines virtuelles traditionnelles, les conteneurs offrent aux organisations informatiques de nouvelles opportunités dans le contrôle de version, le déploiement, la graduation (scaling) et la sécurité. Ce post traitera de ce que sont exactement les conteneurs, pourquoi ils se révèlent si avantageux, comment les utilisateurs les utilisent et des meilleures pratiques pour conteneuriser vos applications Node.js avec Docker. Qu’est-ce qu’un conteneur ? En termes simples, les conteneurs exécutent des instances d’ images de conteneur. Les images sont des alternatives en couches aux disques de machines virtuelles (VMD) qui permettent aux applications d’être extraites de l’environnement dans lequel elles sont réellement exécutées. Les images conteneur sont exécutables, logiciel isolé avec accès aux ressources de l’hôte, au réseau et au système de fichiers. Ces images sont créées avec leurs propres outils système, bibliothèques, code, environnement d’exécution et dépendances associées codées en dur. Cela permet aux conteneurs d’être filés indépendamment de l’environnement. Cette approche “tout-en-un” aide à résoudre les problèmes d’application indépendante, en améliorant la sécurité des systèmes et en facilitant le débogage. Contrairement aux machines virtuelles traditionnelles, les images de conteneur donnent à chacune de ses instances un accès partagé au système d’exploitation hôte via une exécution de conteneur. Cet accès partagé aux ressources du système hôte permet d’obtenir des performances et des ressources qui ne sont pas trouvées dans d’autres méthodes de virtualisation.  Imaginez une image de conteneur qui nécessite 500 Mo. Dans un environnement conteneurisé, ces 500 Mo peuvent être partagés entre des centaines de conteneurs en supposant qu’ils fonctionnent tous sur la même image de base. D’un autre côté, les machines virtuelles auraient besoin de 500 Mo par machine virtuelle . Cela rend les conteneurs beaucoup plus adaptés aux horizontal scaling et aux environnements restreints aux ressources. Pourquoi les conteneurs d’applications ? La légèreté et la reproductibilité des conteneurs en ont fait une option de plus en plus utilisée par les entreprises souhaitant développer des applications logicielles évolutives, hautement disponibles et contrôlées par les versions. Les conteneurs offrent plusieurs avantages clés aux développeurs: Léger et économe en ressources. Par rapport aux machines virtuelles, qui génèrent des copies de leur système d’exploitation hôte pour chaque application ou processus, les conteneurs ont nettement moins d’impact sur la mémoire, l’utilisation du processeur et l’espace disque. Immuable. Les conteneurs sont générés à partir d’une seule source vérifiée, une image. Si des modifications sont validées sur une image, une nouvelle image est créée . Cela rend les changements d’image de conteneur faciles à suivre et les restaurations de déploiement intuitives. La reproductibilité et la stabilité des conteneurs permettent aux équipes de développement d’éviter la dérive de la configuration, ce qui simplifie considérablement le test de version et la mise en miroir des environnements de développement et de production. Portable. La nature isolée et autonome des conteneurs en fait un excellent choix pour les applications qui doivent fonctionner sur une multitude de services, de plates-formes et d’environnements. Ils peuvent fonctionner sous Linux, Windows et macOS. Fournissez-les depuis le cloud, sur site ou là où votre infrastructure l’exige. Évolutif et hautement disponible. Les conteneurs sont facilement reproductibles et peuvent répondre dynamiquement aux demandes de trafic, grâce aux services d’orchestration tels que les instances de conteneur Azure, Google Cloud Engine et Amazon ECS, qui facilitent et accélèrent la création ou le retrait de conteneurs de votre infrastructure. Cas d’utilisation de conteneurs d’applications Toutes les applications et les organisations n’auront pas les mêmes besoins en infrastructure. Les avantages susmentionnés des conteneurs les rendent particulièrement aptes à répondre aux besoins suivant: DEVOPS ORGANISATIONS Pour les équipes qui travaillent à pratiquer «l’infrastructure comme code» et qui cherchent à adopter le paradigme DevOps, les conteneurs offrent des opportunités inégalées. Leur portabilité, leur résistance à la dérive de configuration et leur temps de démarrage rapide font des conteneurs un excellent outil pour tester rapidement et de manière reproductible différents environnements de code, indépendamment de la machine ou de l’emplacement. MICROSERVICE ET ARCHITECTURES DISTRIBUÉES Une expression courante dans le développement de microservices est «faites une chose et faites-le bien», et cela s’harmonise étroitement avec les conteneurs d’applications. Les conteneurs offrent un excellent moyen d’envelopper les microservices et de les isoler de l’environnement d’application plus large. Ceci est très utile lorsque vous souhaitez mettre à jour des (micro-) services spécifiques d’une suite d’applications sans mettre à jour l’ensemble de l’application. TESTS A / B Les conteneurs facilitent le déploiement de plusieurs versions de la même application. Lorsqu’ils sont associés à des déploiements incrémentaux , les conteneurs peuvent maintenir votre application dans un état dynamique et réactif aux tests. Voulez-vous tester une nouvelle fonctionnalité de performance? Faites défiler un nouveau conteneur, ajoutez des mises à jour, acheminez 1% du trafic vers celui-ci et collectez des commentaires sur les utilisateurs et les performances. À mesure que les changements se stabilisent et que votre équipe décide de l’appliquer à l’application en général, les conteneurs peuvent rendre cette transition fluide et efficace. Conteneurs et Node.js En raison de la pertinence des conteneurs d’applications pour les environnements d’application ciblés, Node.js est sans doute le meilleur moteur d’exécution pour la conteneurisation. Dépendances explicites. Les applications Node.js conteneurisées peuvent verrouiller les arborescences de dépendance et gérer des fichiers stables package.json , package-lock.json ou npm-shrinkwrap.json . Démarrage rapide et redémarrage. Les conteneurs sont légers et démarrent rapidement, ce qui en fait une paire stratégique pour les applications Node.js. L’une des fonctionnalités les plus appréciées de Node.js est son temps de démarrage impressionnant. Cette performance de démarrage robuste obtient des processus terminés redémarrés rapidement et les applications stabilisées; La conteneurisation fournit une solution évolutive pour maintenir cette performance. Scaling au niveau du processus. Semblable à la meilleure pratique de Node.js consistant à faire tourner plus de processus au lieu de plus de threads, un environnement conteneurisé augmentera le nombre de processus en augmentant le nombre de conteneurs. Cet horizontal scaling crée de la redondance et permet de maintenir les applications hautement disponibles, sans le coût significatif des ressources d’une nouvelle machine virtuelle par processus. Dockeriser votre application Node.js Présentation de Docker Docker est un système de fichiers en couches pour l’envoi d’images, et permet aux organisations d’abstraire leurs applications de leur infrastructure. Avec Docker, les images sont générées via un fichier Docker. Ce fichier fournit des configurations et des commandes pour générer des images par programme. Chaque commande Docker dans un Dockerfile ajoute un ‘calque’. Plus il y a de couches, plus le conteneur résultant est grand. Voici un exemple simple de Dockerfile:  La commande FROM désigne l’image de base qui sera utilisée; dans ce cas, il s’agit de l’image de la ligne de lancement Node.js 8 LTS. La commande RUN prend les commandes bash comme arguments. Dans la ligne 2, nous créons un répertoire pour placer l’application Node.js. La ligne 3 indique à Docker que le répertoire de travail pour chaque commande après la ligne 3 sera le répertoire de l’application. La ligne 5 copie tout le répertoire courant dans le répertoire courant de l’image, qui est /home/nodejs/app précédemment défini par la commande WORKDIR de manière similaire. Sur la ligne 6, nous installons l’installation de production. Enfin, sur la ligne 8, nous transmettons à Docker une commande et un argument pour exécuter l’application Node.js à l’intérieur du conteneur. L’exemple ci-dessus fournit un Dockerfile de base, mais finalement problématique. Dans la section suivante, nous examinerons certaines des meilleures pratiques de Dockerfile pour exécuter Node.js en production. Meilleures pratiques Dockerfile NE PAS EXÉCUTER L’APPLICATION EN TANT QUE ROOT Assurez-vous que l’application exécutée dans le conteneur Docker n’est pas exécutée en tant que root.  Dans l’exemple ci-dessus, quelques lignes de code ont été ajoutées à l’exemple Dockerfile d’origine pour extraire l’image de la dernière version LTS de Node.js, ainsi que pour ajouter et définir un nouvel utilisateur, nodejs . De cette façon, dans le cas où une vulnérabilité de l’application est exploitée, et que quelqu’un réussit à entrer dans le conteneur au niveau du système, au mieux, ce sont des utilisateurs nodejs qui n’ont pas d’autorisations root et n’existent pas sur l’hôte. CACHE NODE_MODULES Docker construit chaque ligne d’un Dockerfile individuellement. Cela forme les “couches” de l’image Docker. Au fur et à mesure qu’une image est construite, Docker met en cache chaque couche.  Sur la ligne 9 du Dockerfile ci-dessus, le fichier package.json est copié dans le répertoire de travail établi sur la ligne 7. Après le npm install sur la ligne 10, la ligne 11 copie le répertoire courant dans le répertoire de travail (l’image). Si aucune modification n’est apportée à votre package.json , Docker ne reconstruira pas la couche d’image npm install, ce qui peut considérablement améliorer les temps de construction. CONFIGUREZ VOTRE ENVIRONNEMENT Il est important de définir explicitement les variables d’environnement que votre application Node.js s’attend à rester constante tout au long du cycle de vie du conteneur.  DockerHub fournit une ressource centralisée pour la découverte d’images de conteneur, la distribution et la gestion des modifications, la collaboration entre utilisateurs et équipes et l’automatisation du flux de travail tout au long du pipeline de développement’.\nPour associer la CLI Docker à votre compte DockerHub, utilisez la docker login  docker login [OPTIONS] [SERVER] : docker login [OPTIONS] [SERVER] COMPTES GITHUB PRIVÉS ET MODULES NPM Docker exécute ses builds à l’intérieur d’un sandbox et cet environnement sandbox n’a pas accès à des informations telles que les clés ssh ou les informations d’identification npm. Pour contourner cette contrainte, quelques options recommandées sont disponibles pour les développeurs: Stocker les clés et les informations d’identification sur le système CI / CD. Les problèmes de sécurité d’avoir des informations d’identification sensibles à l’intérieur de la construction Docker peuvent être évités entièrement en ne les mettant jamais là en premier lieu. Au lieu de cela, stockez-les et récupérez-les dans le système CI / CD de votre infrastructure, et copiez manuellement les dépendances privées dans l’image. Utilisez un serveur npm interne. À l’aide d’un outil comme Verdaccio, configurez un proxy npm qui garde le flux des modules internes et des informations d’ identification privées . SOYEZ EXPLICITE AVEC LES TAGS Les balises aident à différencier les différentes versions d’images. Les balises peuvent être utilisées pour identifier les builds, les équipes qui travaillent sur l’image et littéralement toute autre désignation utile à une organisation pour gérer le développement des images. Si aucune balise n’est ajoutée explicitement, Docker assignera une balise par défaut à latest après la docker build. En tant que tag, le développement est le latest en date, mais peut être très problématique dans les environnements de production et de mise en scène. Pour éviter les problèmes latest , soyez explicites avec vos balises de construction. Voici un exemple de script attribuant des balises avec des variables d’environnement pour le git sha, le nom de la branche et le numéro de build de la construction, tous les trois pouvant être très utiles dans la gestion des versions, du débogage et du déploiement:  En savoir plus sur le marquage ici. Conteneurs et gestion des processus Les conteneurs sont conçus pour être légers et bien adaptés au niveau du processus, ce qui contribue à simplifier la gestion des processus: si le processus se termine, le conteneur se ferme. Cependant, cette cartographie 1:1 est une idéalisation qui n’est pas toujours maintenue dans la pratique. Comme les conteneurs Docker ne sont pas fournis avec un gestionnaire de processus, ajoutez un outil pour une gestion simple des processus. dumb-init de Yelp est un superviseur de processus simple et léger et un système d’initialisation conçu pour fonctionner en tant que PID 1 dans des environnements de conteneur. Cette désignation PID 1 pour le processus dumb-init est normalement affectée à un conteneur Linux en cours d’exécution et possède ses propres idiosyncrasies de signalisation du noyau qui compliquent la gestion des processus. Dumb-init fournit un niveau d’abstraction qui lui permet d’agir comme un proxy de signal, assurant le comportement attendu du processus. Ce qu’il faut inclure dans vos conteneurs d’applications Le principal avantage des conteneurs est qu’ils ne fournissent que ce qui est nécessaire. Gardez cela à l’esprit lorsque vous ajoutez des calques à vos images. Voici une liste de contrôle à inclure lors de la création d’images de conteneur: Votre code d’application et ses dépendances. Variables d’environnement nécessaires. Un proxy de signal simple pour la gestion de processus, comme dumb-init.\nC’est tout. Conclusion Les conteneurs sont une solution de virtualisation moderne mieux adaptée aux infrastructures nécessitant un partage efficace des ressources, des délais de démarrage rapides et une mise à l’échelle rapide. Les organisations DevOps utilisent des conteneurs d’applications pour implémenter ‘l’infrastructure en tant que code’, des équipes développant des microservices et s’appuyant sur des architectures distribuées et des groupes d’assurance qualité (QA) tirant parti de stratégies telles que les tests A/B et les déploiements incrémentaux en production. Tout comme l’approche recommandée pour Node.js monothread est 1 processus: 1 application, la meilleure pratique pour les conteneurs d’applications est 1 processus: 1 conteneur. Cette relation en miroir fait sans doute de Node.js l’environnement d’exécution le plus approprié pour le développement de conteneurs. Docker est une plate-forme ouverte pour le développement, l’expédition et l’exécution d’applications conteneurisées. Docker vous permet de séparer vos applications de votre infrastructure afin de pouvoir livrer des logiciels rapidement. Lorsque vous utilisez Docker avec Node.js, gardez à l’esprit: Ne lancez pas l’application en tant que root Cache node_modules Utilisez votre système CI / CD ou un serveur interne pour conserver les informations d’identification sensibles hors de l’image du conteneur Soyez explicite avec les balises de construction Gardez les récipients légers !","timeToRead":14,"frontmatter":{"title":"Conteneuriser des applications Node.js avec Docker","subtitle":"La légèreté et la reproductibilité des conteneurs en ont fait une option de plus en plus utilisée par les entreprises souhaitant développer des applications logicielles évolutives, hautement disponibles et contrôlées par les versions.","tags":["Docker","Node.js","Javascript","DevOps"],"date":"2018-05-11T08:00:00.000Z","image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgX/xAAVAQEBAAAAAAAAAAAAAAAAAAACA//aAAwDAQACEAMQAAAB01MmaaUEf//EABkQAAIDAQAAAAAAAAAAAAAAAAECABETEv/aAAgBAQABBQIuKDct1cwW8ReQn//EABcRAQADAAAAAAAAAAAAAAAAAAACERL/2gAIAQMBAT8BqLL/xAAYEQACAwAAAAAAAAAAAAAAAAAAAQIREv/aAAgBAgEBPwFuVmmf/8QAGhAAAgIDAAAAAAAAAAAAAAAAAAEQMSFBYf/aAAgBAQAGPwLsYNlstn//xAAaEAEAAwADAAAAAAAAAAAAAAABABEhgbHx/9oACAEBAAE/IcACCRgtUqAWHkxa23U9Sf/aAAwDAQACAAMAAAAQtP8A/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQARUf/aAAgBAwEBPxAAxkdv/8QAGBEAAgMAAAAAAAAAAAAAAAAAAAERMVH/2gAIAQIBAT8QYkqFgf/EABwQAQADAAIDAAAAAAAAAAAAAAEAESFBcTGRsf/aAAgBAQABPxA9p8EzIu7rChBd+Q3XwtSb7+wiB2HEr0inD1H/2Q==","aspectRatio":1.5337423312883436,"src":"/static/aa737b43d3d846778b615068a6705bf0/8a760/container.jpg","srcSet":"/static/aa737b43d3d846778b615068a6705bf0/68709/container.jpg 310w,\n/static/aa737b43d3d846778b615068a6705bf0/53593/container.jpg 620w,\n/static/aa737b43d3d846778b615068a6705bf0/8a760/container.jpg 1240w,\n/static/aa737b43d3d846778b615068a6705bf0/0e6ff/container.jpg 1860w,\n/static/aa737b43d3d846778b615068a6705bf0/883ab/container.jpg 2000w","sizes":"(max-width: 1240px) 100vw, 1240px"}}},"author":{"id":"ludo","bio":"Développeur senior. Fullstack + DevOps","avatar":{"children":[{"__typename":"ImageSharp","fixed":{"src":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png"}}]}}},"fields":{"layout":"post","slug":"/docker-nodejs/"}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"tag":"Docker","tagURL":"docker","limit":9,"skip":0,"numPages":1,"currentPage":1}}}