{"componentChunkName":"component---src-templates-post-tsx","path":"/kindle/","webpackCompilationHash":"ba1a271305926245155b","result":{"data":{"logo":{"childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAABFUlEQVQY023PvUrDUBTA8ZuCtoMoOLQ4dWhN14x2kEKXFkGoohQ/QBexOHRycAidKkgHHRq69APRoTjFJYODIA6+gSBYfYMmfYLE/5VT6NALP845NyeHc9UoCHZRQvonCLKKE4ZhAXYURTsYoE9dIy5iCzfUJnEdV+RF4iu6ikFH2EPxazzOcJmg4Rnn5C8ysIEOHqTe5/sT3qXOwYOtRr5/wLAqzpCTDXu4p2ETtyjgGJ/cX+se8jeU9fa4RBt5vWENpjzdkoGPcGg4RQsbOMEFmnBRRwVDHEK/yFXfvr/CoPjvZLKcdByDyzWGeajigzorGy0oOeRJiUtITe/pX1XzDk3buIMltSFR/zTtic3060X+8z8PsEUt8G3LVQAAAABJRU5ErkJggg==","width":400,"height":128,"src":"/static/2b5eaa0de166a8b5faebad4955c2200c/647de/ghost-logo.png","srcSet":"/static/2b5eaa0de166a8b5faebad4955c2200c/647de/ghost-logo.png 1x"}}},"markdownRemark":{"html":"<p>Si vous avez un <a href=\"https://www.amazon.fr/dp/B00QJDO0QC\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kindle</a> d’Amazon, vous ne le savez peut-être pas, mais vous possédez une adresse mail ….@kindle.com qui vous permet de vous envoyer des livres et documents directement sur votre liseuse.</p>\n<p>Pour cela, il faut ajouter votre email <a href=\"https://www.amazon.com/hz/mycd/myx#/home/settings/payment?tag=amazon0d16-21\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">via cette page</a>, dans la section <strong>“Settings”</strong> > <strong>“Personal Document Settings”</strong> > <strong>“Approved Personal Document E-mail List”</strong>.</p>\n<p>Et juste au-dessus, vous devriez voir dans la section <strong>“Send-to-Kindle E-Mail Settings”</strong>, le ou les emails @kindle.com associés avec chacun de vos appareils Kindle.</p>\n<p>En effet, en envoyant un fichier depuis votre email référencé vers votre email kindle.com, vous pouvez le transférer vers votre liseuse sans avoir besoin de brancher le moindre câble ou d’installer le moindre soft.</p>\n<p>Seulement, Amazon autorise l’envoi uniquement des fichiers aux formats suivants :</p>\n<ul>\n<li>Kindle Format (.MOBI, .AZW)</li>\n<li>Microsoft Word (.DOC, .DOCX)</li>\n<li>HTML (.HTML, .HTM)</li>\n<li>RTF (.RTF)</li>\n<li>Text (.TXT)</li>\n<li>JPEG (.JPEG, .JPG)</li>\n<li>GIF (.GIF)</li>\n<li>PNG (.PNG)</li>\n<li>BMP (.BMP)</li>\n<li>PDF (.PDF)</li>\n</ul>\n<p>Malheureusement, comme vous pouvez le voir, <strong>pas de format epub</strong>. Obligé de brancher le Kindle à votre ordinateur et d’utiliser Calibre ?</p>\n<p>Non, non, non. Il suffit de vous rendre sur le site <a href=\"https://www.sendepubtokindle.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><strong>Send epub to Kindle</strong></a> , puis de renseigner les infos demandées, à savoir votre email référencé, l’email Kindle et de glisser-déposer le livre au format epub de votre choix.</p>\n<p>Cliquez ensuite sur le bouton vert « Upload &#x26; Send » et tadaaaa, au bout de quelques secondes, le livre apparaitra sur votre liseuse Kindle.</p>\n<p>Elle est pas belle la vie ?</p>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Si vous avez un "},{"type":"element","tagName":"a","properties":{"href":"https://www.amazon.fr/dp/B00QJDO0QC","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"text","value":"Kindle"}]},{"type":"text","value":" d’Amazon, vous ne le savez peut-être pas, mais vous possédez une adresse mail ….@kindle.com qui vous permet de vous envoyer des livres et documents directement sur votre liseuse."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour cela, il faut ajouter votre email "},{"type":"element","tagName":"a","properties":{"href":"https://www.amazon.com/hz/mycd/myx#/home/settings/payment?tag=amazon0d16-21","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"text","value":"via cette page"}]},{"type":"text","value":", dans la section "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"“Settings”"}]},{"type":"text","value":" > "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"“Personal Document Settings”"}]},{"type":"text","value":" > "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"“Approved Personal Document E-mail List”"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Et juste au-dessus, vous devriez voir dans la section "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"“Send-to-Kindle E-Mail Settings”"}]},{"type":"text","value":", le ou les emails @kindle.com associés avec chacun de vos appareils Kindle."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"En effet, en envoyant un fichier depuis votre email référencé vers votre email kindle.com, vous pouvez le transférer vers votre liseuse sans avoir besoin de brancher le moindre câble ou d’installer le moindre soft."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Seulement, Amazon autorise l’envoi uniquement des fichiers aux formats suivants :"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Kindle Format (.MOBI, .AZW)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Microsoft Word (.DOC, .DOCX)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"HTML (.HTML, .HTM)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"RTF (.RTF)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Text (.TXT)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"JPEG (.JPEG, .JPG)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"GIF (.GIF)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"PNG (.PNG)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"BMP (.BMP)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"PDF (.PDF)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Malheureusement, comme vous pouvez le voir, "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"pas de format epub"}]},{"type":"text","value":". Obligé de brancher le Kindle à votre ordinateur et d’utiliser Calibre ?"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Non, non, non. Il suffit de vous rendre sur le site "},{"type":"element","tagName":"a","properties":{"href":"https://www.sendepubtokindle.com/","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Send epub to Kindle"}]}]},{"type":"text","value":" , puis de renseigner les infos demandées, à savoir votre email référencé, l’email Kindle et de glisser-déposer le livre au format epub de votre choix."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Cliquez ensuite sur le bouton vert « Upload & Send » et tadaaaa, au bout de quelques secondes, le livre apparaitra sur votre liseuse Kindle."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Elle est pas belle la vie ?"}]}],"data":{"quirksMode":false}},"excerpt":"Si vous avez un Kindle d’Amazon, vous ne le savez peut-être pas, mais vous possédez une adresse mail ….@kindle.com qui vous permet de vous envoyer des livres et documents directement sur votre liseuse. Pour cela, il faut ajouter votre email via cette page, dans la section “Settings” > “Personal Document Settings” > “Approved Personal Document E-mail List”. Et juste au-dessus, vous devriez voir dans la section “Send-to-Kindle E-Mail Settings”, le ou les emails @kindle.com associés avec chacun de vos appareils Kindle. En effet, en envoyant un fichier depuis votre email référencé vers votre email kindle.com, vous pouvez le transférer vers votre liseuse sans avoir besoin de brancher le moindre câble ou d’installer le moindre soft. Seulement, Amazon autorise l’envoi uniquement des fichiers aux formats suivants : Kindle Format (.MOBI, .AZW) Microsoft Word (.DOC, .DOCX) HTML (.HTML, .HTM) RTF (.RTF) Text (.TXT) JPEG (.JPEG, .JPG) GIF (.GIF) PNG (.PNG) BMP (.BMP) PDF (.PDF) Malheureusement, comme vous pouvez le voir, pas de format epub. Obligé de brancher le Kindle à votre ordinateur et d’utiliser Calibre ? Non, non, non. Il suffit de vous rendre sur le site Send epub to Kindle , puis de renseigner les infos demandées, à savoir votre email référencé, l’email Kindle et de glisser-déposer le livre au format epub de votre choix. Cliquez ensuite sur le bouton vert « Upload & Send » et tadaaaa, au bout de quelques secondes, le livre apparaitra sur votre liseuse Kindle. Elle est pas belle la vie ?","timeToRead":1,"frontmatter":{"title":"Comment envoyer un epub vers une Kindle sans utiliser Calibre ni de cable USB ?","subtitle":"","userDate":"24 November 2018","date":"2018-11-24T08:00:00.000Z","tags":["Kindle","Ebook"],"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAQFA//EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAGa0ziTSqWf/8QAGBABAQEBAQAAAAAAAAAAAAAAAQIDACL/2gAIAQEAAQUCy0ItmMp9HVjK1mHMj3//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPwFH/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQIBAT8BV//EABsQAAIDAAMAAAAAAAAAAAAAAAABAhExEBIh/9oACAEBAAY/As8xkujuUlRnFos//8QAGRABAAMBAQAAAAAAAAAAAAAAAQARITFB/9oACAEBAAE/ISa6jh2N3hhGocLS2JPOElOjWf/aAAwDAQACAAMAAAAQ2P8A/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAEDAQE/EIw//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/EK2//8QAGxABAQACAwEAAAAAAAAAAAAAAREAMSFRYUH/2gAIAQEAAT8QFwmLUI775mAebFhqWTRLvCPHnyYECp4Z6B6G/HGBI1nef//Z","aspectRatio":1.5,"src":"/static/e96dc41e5ffd5680b39408b75434d7e0/14dee/kindle.jpg","srcSet":"/static/e96dc41e5ffd5680b39408b75434d7e0/f8f18/kindle.jpg 930w,\n/static/e96dc41e5ffd5680b39408b75434d7e0/0e6ff/kindle.jpg 1860w,\n/static/e96dc41e5ffd5680b39408b75434d7e0/14dee/kindle.jpg 1920w","sizes":"(max-width: 1920px) 100vw, 1920px"}}},"author":{"id":"ludo","name":"Wyffels Ludovic","bio":"Développeur senior. Fullstack + DevOps","avatar":{"children":[{"__typename":"ImageSharp","fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAABMUlEQVQ4y2MwsXf5T03MMGogGBvbOYNpUwdXOIbJwdgwNQQNhCk0snX6r2thC8Y6QGxg7QCWA/FBcrgMxepCkAZrV6//EYmpYBydkvHfMzjiv5mj2//whJT/Nm7ecEMJGgjykp6V/f+AqLj/O/Ye+L8diA8dO/m/pbv/v72n3/+tu/f9D45N/K9naYcSFESFoRXQlSCX2rh7g/kgr1u5epIWhiAMCi/3wLD/fVNn/u+fNgtMT5g+6//kmXOB/Jn/PYLCwWrINnDijDlAPBvKJ8NAZC+DIgCkGYRBbJAYSV5GjpTte/b/PwiMkLj0nP8xqVn/Dxw9AY6kwOh40iIFlmzCgUkmKjnjvx0wdu08fMFskJi1mxfxyQY9YetAEzJyQic5YaNnPeTgIDnrjZaHJGMACtTMXoVAJ6sAAAAASUVORK5CYII=","width":400,"height":400,"src":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png","srcSet":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png 1x"}}]}}}},"relatedPosts":{"totalCount":1,"edges":[{"node":{"id":"a1aa2a88-17e3-5155-b66b-ca06e862f6c6","timeToRead":1,"excerpt":"Si vous avez un Kindle d’Amazon, vous ne le savez peut-être pas, mais vous possédez une adresse mail ….@kindle.com qui vous permet de vous envoyer des livres et documents directement sur votre liseuse. Pour cela, il faut ajouter votre email via cette page, dans la section “Settings” > “Personal Document Settings” > “Approved Personal Document E-mail List”. Et juste au-dessus, vous devriez voir dans la section “Send-to-Kindle E-Mail Settings”, le ou les emails @kindle.com associés avec chacun de vos appareils Kindle. En effet, en envoyant un fichier depuis votre email référencé vers votre email kindle.com, vous pouvez le transférer vers votre liseuse sans avoir besoin de brancher le moindre câble ou d’installer le moindre soft. Seulement, Amazon autorise l’envoi uniquement des fichiers aux formats suivants : Kindle Format (.MOBI, .AZW) Microsoft Word (.DOC, .DOCX) HTML (.HTML, .HTM) RTF (.RTF) Text (.TXT) JPEG (.JPEG, .JPG) GIF (.GIF) PNG (.PNG) BMP (.BMP) PDF (.PDF) Malheureusement, comme vous pouvez le voir, pas de format epub. Obligé de brancher le Kindle à votre ordinateur et d’utiliser Calibre ? Non, non, non. Il suffit de vous rendre sur le site Send epub to Kindle , puis de renseigner les infos demandées, à savoir votre email référencé, l’email Kindle et de glisser-déposer le livre au format epub de votre choix. Cliquez ensuite sur le bouton vert « Upload & Send » et tadaaaa, au bout de quelques secondes, le livre apparaitra sur votre liseuse Kindle. Elle est pas belle la vie ?","frontmatter":{"title":"Comment envoyer un epub vers une Kindle sans utiliser Calibre ni de cable USB ?","subtitle":""},"fields":{"slug":"/kindle/"}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/kindle/","prev":{"excerpt":"J’ai installé Docker Swarm et Kubernetes sur deux machines virtuelles. J’ai trouvé que Docker Swarm est très facile à installer et à configurer, alors que Kubernetes est un peu plus difficile à installer mais reste simple à utiliser. Introduction Cela fait des années que je veux essayer des conteneurs: la configuration manuelle de serveurs prend du temps, n’est pas reproductible et risque d’introduire des différences entre mon environnement de test local et la production. Les containers offrent une solution à tous ces problèmes et facilite beaucoup l’exécution d’instances supplémentaires d’une application. Cela peut rendre un service plus évolutif. Pour exécuter un service évolutif, vous avez besoin d’un moteur Container Orchestration qui répartit la charge en exécutant des conteneurs sur plusieurs ordinateurs et en envoyant des demandes à chaque instance de l’application. Docker Swarm et Kubernetes sont deux moteurs d’orchestration populaires. J’ai décidé d’essayer les deux en déployant la même application avec chaque moteur. Création du conteneur J’ai décidé d’utiliser Samba pour l’application de test. Samba est un serveur de fichiers populaire permettant aux ordinateurs Linux de partager des fichiers avec des ordinateurs Windows. Il communique via TCP sur le port 445. C’est la première fois que je travaille avec Docker, j’ai donc modifié un conteneur Samba standard afin d’inclure le fichier que je voulais servir. Après le tutoriel de Docker, j’ai lancé manuellement le conteneur à partir de la ligne de commande pour vérifier son fonctionnement: Et en effet, j’ai pu me connecter au serveur Samba dans le conteneur avec smbclient Maintenant que je sais que le conteneur fonctionne, je peux l’utiliser dans un moteur d’orchestration de conteneur. Préparer les machines virtuelles J’ai créé deux machines virtuelles exécutant Ubuntu 18.04 dans VirtualBox. J’ai ajouté une carte réseau supplémentaire à chaque machine virtuelle, configurée pour le réseau interne afin qu’ils puissent se parler: https://cdn-images-1.medium.com/max/1600/1*chCjRdcU_mV9ioAyQ7oB5A.png Ensuite, j’ai ajouté un serveur DHCP pour attribuer des adresses IP à chaque machine virtuelle: Les machines virtuelles peuvent désormais communiquer entre elles. Cela donne à ma machine virtuelle principale l’adresse IP 10.133.7.100. Docker Swarm Docker Swarm est un moteur d’orchestration de conteneur intégré à Docker lui-même. Quand je l’ai trouvé, j’étais sceptique: pourquoi l’utiliser à la place des Kubernetes, beaucoup plus célèbres? La réponse: Docker Swarm est axé sur la simplicité par rapport à la configuration. Cela ressemblait à l’iOS des moteurs d’orchestration de conteneurs par rapport à l’Android de Kubernetes. Mise en place de Docker Swarm Docker Swarm est facile à installer: il suffit d’installer Docker et docker-compose. Ensuite, après le tutoriel officiel, j’ai exécuté la seule commande nécessaire pour démarrer le noeud du gestionnaire, en transmettant l’adresse IP de la machine virtuelle actuelle: C’est tout: le moteur Docker tourne maintenant en mode Swarm. Ensuite, j’ai déployé un registre privé Docker afin que les autres noeuds puissent extraire des images, en suivant à nouveau les instructions d’installation: Déploiement de l’application Docker Swarm utilise le format Docker Compose pour spécifier les conteneurs à exécuter et les ports qu’ils exportent. Après le didacticiel Docker Compose, j’ai créé ce manifeste Docker Compose: Cela indique à Docker Compose de créer le fichier Docker à partir du répertoire «sambaonly», d’upload/pull les conteneurs construits vers mon registre privé nouvellement configuré et d’exporter le port 445 à partir du conteneur. Pour déployer ce manifeste, j’ai suivi le tutoriel de Docker Swarm. J’ai d’abord utilisé Docker Compose pour créer et télécharger le conteneur dans le registre privé: Une fois le conteneur créé, l’application peut être déployée avec la commande docker stack deploy, en spécifiant le nom du service: Et maintenant, l’application fonctionne sous Samba Swarm. J’ai testé qu’il fonctionne toujours avec smbclient: Ajout d’un autre noeud Ici encore, la simplicité de Docker Swarm transparaît. Pour installer un deuxième noeud, j’ai d’abord installé Docker, puis exécuté la commande que Docker m’avait donnée lors de l’installation de swarm: Pour exécuter mon application sur les deux nœuds, j’ai exécuté la commande scale de Docker Swarm sur le nœud du gestionnaire: Sur le nouveau noeud de travail, le nouveau conteneur est apparu: Test de l’équilibrage de charge (load balancing) Docker Swarm comprend un load balancing intégré appelé routeur Mesh: les demandes adressées à l’adresse IP de tout noeud sont automatiquement réparties sur l’ensemble de Swarm. Pour tester cela, j’ai établi 1000 connexions à l’adresse IP du noeud du gestionnaire avec nc: Samba génère un nouveau processus pour chaque connexion. Par conséquent, si l’équilibrage de la charge fonctionne, je m’attendrais à environ 500 processus Samba sur chaque noeud de Swarm. C’est bien ce qui se passe. Après avoir exécuté le script pour établir 1000 connexions, j’ai vérifié le nombre de processus Samba sur le gestionnaire (10.133.7.100): Et sur le noeud travailleur (10.133.7.50): Ainsi, exactement la moitié des demandes adressées au noeud de gestion ont été redirigées de manière magique vers le premier noeud de travail, ce qui montre que le cluster Swarm fonctionne correctement. J’ai trouvé que Docker Swarm était très facile à installer et il fonctionnait bien sous une charge (légère). Kubernetes Kubernetes est en train de devenir l’industrie standard de l’orchestration de conteneurs. C’est beaucoup plus flexible que Docker Swarm, mais cela rend plus difficile la configuration. Je l’ai trouvé pas si difficile, cependant. Pour cette expérience, au lieu d’utiliser un environnement de développement Kubernetes pré-construit tel que minikube, j’ai décidé de configurer mon propre cluster, à l’aide de Kubadm, WeaveNet et MetalLB. Mise en place de Kubernetes Kubernetes à la réputation d’être difficile à configurer: vous avez entendu le processus complexe en plusieurs étapes du didacticiel Kubernetes the Hard Way Les développeurs de Kubernetes ont simplifié l’utilisation de kubeadm. Malheureusement, Kubernetes étant si flexible, le tutoriel sur kubeadm ne couvre pas encore quelques étapes. J’ai donc dû déterminer le réseau et l’équilibreur de charge à utiliser moi-même. Voici ce que j’ai fini par lancer. J’ai d’abord dû désactiver Swap sur chaque noeud: Ensuite, j’ai configuré le noeud maître (10.133.7.100) avec la commande suivante: L’option --pod-network-cidr attribue une adresse réseau interne à tous les noeuds du réseau, utilisée pour les communications internes dans Kubernetes. Les options --apiserver-advertise-address et --apiserver-cert-extra-sans ont été ajoutées à cause d’un problème particulier dans l’installation de VirtualBox: la carte virtuelle principale des machines virtuelles (IP 10.0.2.15) ne peut accéder qu’à l’Internet. J’ai dû préciser que d’autres noeuds doivent accéder au maître à l’aide de l’adresse IP 10.133.7.100. Après avoir exécuté cette commande, Kubeadm a affiché quelques instructions: J’ai raté ces instructions la première fois et je n’ai donc pas terminé la configuration. J’ai ensuite passé une semaine entière à me demander pourquoi aucun de mes conteneurs ne fonctionnait! Après avoir enfin lu les instructions, je devais faire trois autres choses: Tout d’abord, je devais exécuter les commandes données par kubeadm pour configurer un fichier de configuration. Par défaut, Kubernetes ne planifie pas les conteneurs sur le nœud maître, mais uniquement sur les noeuds de travail. Comme je n’ai qu’un seul noeud pour le moment, le tutoriel m’a montré cette commande pour autoriser l’exécution de conteneurs sur le seul noeud: Enfin, je devais choisir un réseau pour mon cluster. Installation du réseau Contrairement à Docker Swarm, qui doit utiliser sa propre couche de routage maillé pour la mise en réseau et l’équilibrage de la charge, Kubernetes offre de multiples choix pour la mise en réseau et l’équilibrage de la charge. Le composant de mise en réseau permet aux conteneurs de communiquer en interne. J’ai fait des recherches et cet article comparatif suggérait Flannel ou WeaveNet, car ils sont faciles à configurer. Ainsi, j’ai décidé d’essayer WeaveNet. J’ai suivi les instructions du didacticiel kubeadm pour appliquer la configuration de WeaveNet: Ensuite, pour permettre aux conteneurs de communiquer avec le monde extérieur, j’ai besoin d’un équilibreur de charge. D’après mes recherches, j’ai eu l’impression que la plupart des implémentations de l’équilibreur de charge Kubernetes se concentrent uniquement sur les services HTTP, et non sur le TCP brut. Heureusement, j’ai trouvé MetalLB, un projet récent (vieux d’un an) qui comble cette lacune. Pour installer MetalLB, j’ai suivi son didacticiel de mise en route et j’ai tout d’abord déployé MetalLB: Ensuite, j’ai attribué la plage d’adresses IP 10.133.7.200 à 10.133.7.230 à MetalLB, en créant et en appliquant ce fichier de configuration: Déploiement de l’application Les fichiers de configuration du service de Kubernetes sont plus détaillés que ceux de Docker Swarm, en raison de la flexibilité de Kubernetes. En plus de spécifier le conteneur à exécuter, comme Docker Swarm, je dois spécifier comment chaque port doit être traité. Après avoir lu le tutoriel de Kubernetes, j’ai proposé cette configuration de Kubernetes, composée d’un service et d’un déploiement. https://gist.github.com/ludovicwyffels/911bb25b611f3519745aeee0d53c6447 Ce service demande à Kubernetes d’exporter le port TCP 445 de nos conteneurs Samba vers l’équilibreur de charge. https://gist.github.com/ludovicwyffels/41022da159c539e45027c68776f459d8 Cet objet Deployment indique à Kubernetes d’exécuter mon conteneur et d’exporter un port que le service doit gérer. Notez le replicas: 1 - c’est le nombre d’instances du conteneur que je veux exécuter. Je peux déployer ce service sur Kubernetes en utilisant kubectl apply: Et, après avoir redémarré ma machine virtuelle à quelque reprises, le déploiement a finalement commencé à fonctionner: Mon service est maintenant disponible sur l’adresse IP externe attribuée par MetalLB: Ajout d’un autre noeud Ajouter un autre noeud dans un cluster Kubernetes est beaucoup plus simple: il me suffisait d’exécuter la commande donnée par kubeadm sur le nouvel ordinateur: Bizarreries de ma configuration J’ai dû faire deux changements en raison de la configuration de VirtualBox: Premièrement, comme ma machine virtuelle dispose de deux cartes réseau, je dois indiquer manuellement l’adresse IP de ma machine à Kubernetes. Selon ce problème, je devais éditer Et changer une ligne en avant de redémarrer Kubernetes: L’autre solution concerne le registre Docker: comme le nouveau noeud ne peut accéder à mon registre privé sur le noeud maître, j’ai décidé de procéder à un terrible hack et de partager le registre de mon noeud maître vers la nouvelle machine à l’aide de ssh: Cela transmet le port 5000 du noeud principal, dora (qui exécute le registre Docker) à localhost, où Kubernetes peut le trouver sur cette machine. En production réelle, il est probable que le registre Docker sera hébergé sur une machine distincte, afin que tous les noeuds puissent y accéder. “Scaling” de l’application Lors de la deuxième installation de l’ordinateur, j’ai modifié mon déploiement d’origine pour ajouter une autre instance de l’application: Après avoir redémarré le maître et le worker à quelques reprises, la nouvelle instance de mon application a finalement quitté le statut de CreatingContainer et a commencé à s’exécuter: Test de l’équilibrage de charge J’ai utilisé la même procédure pour ouvrir 1000 connexions à Samba s’exécutant sur Kubernetes. Le résultat est intéressant. Master: Worker: Kubernetes / MetalLB a également équilibré la charge sur les deux machines, mais la machine principale a eu un peu moins de connexions que le worker. Je me demande pourquoi. Quoi qu’il en soit, cela montre que j’ai finalement réussi à installer Kubernetes après plusieurs détours. Comparaison et conclusion Fonctionnalités communes aux deux: les deux peuvent gérer des conteneurs et gérer intelligemment les demandes d’équilibrage de charge sur la même application TCP sur deux machines virtuelles différentes. Les deux ont une bonne documentation pour la configuration initiale. Les atouts de Docker Swarm: une configuration simple, aucune configuration requise, une intégration étroite avec Docker. Les points forts de Kubernetes: composants souples, nombreuses ressources disponibles et add-ons. Kubernetes vs Docker Swarm est un compromis entre simplicité et flexibilité. J’ai trouvé plus facile d’installer Docker Swarm, mais je ne peux pas, par exemple, échanger l’équilibreur de charge contre un autre composant. Il n’ya aucun moyen de le configurer: je devrais tout désactiver en même temps. Sur Kubernetes, il m’a fallu un certain temps pour trouver la bonne configuration, mais en échange, je pouvais changer certaines parties de mon cluster selon les besoins et installer facilement des add-ons, tels qu’un tableau de bord sophistiqué. Si vous voulez juste essayer Kubernetes sans toute cette configuration, je vous suggère d’utiliser minikube, qui offre une machine virtuelle de cluster Kubernetes prédéfinie, aucune installation requise. Enfin, je suis impressionné par le fait que les deux moteurs ont pris en charge les services TCP bruts: d’autres fournisseurs de services d’infrastructure en tant que services, tels que Heroku ou Glitch, ne prennent en charge que l’hébergement de sites Web HTTP. La disponibilité des services TCP signifie que l’on peut déployer ses propres serveurs de base de données, ses serveurs de cache et même ses serveurs Minecraft en utilisant les mêmes outils pour déployer des applications Web, faisant de la gestion de l’orchestration de conteneurs une compétence très utile. En conclusion, si je construisais un cluster, j’utiliserais Docker Swarm. Si je payais quelqu’un d’autre pour construire un cluster pour moi, je demanderais Kubernetes. Ce que j’ai appris Comment travailler avec les conteneurs Docker Comment configurer un cluster Docker Swarm à deux noeuds Comment configurer un cluster Kubernetes à deux noeuds et quels choix fonctionneraient pour une application basée sur TCP Comment déployer une application sur Docker Swarm et Kubernetes Comment réparer quoi que ce soit en redémarrant un ordinateur assez souvent, comme si je utilisais encore Windows 98 Kubernetes et Docker Swarm ne sont pas aussi intimidants qu’ils semblent","timeToRead":16,"frontmatter":{"title":"Docker Swarm vs Kubernetes","subtitle":"J'ai trouvé que Docker Swarm est très facile à installer et à configurer, alors que Kubernetes est un peu plus difficile à installer mais reste simple à utiliser.","tags":["Kubernetes","Docker","DevOps"],"category":["DevOps"],"date":"2018-11-01T08:00:00.000Z","draft":false,"image":{"childImageSharp":{"fluid":{"aspectRatio":1.7772511848341233,"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQDBf/EABYBAQEBAAAAAAAAAAAAAAAAAAIAAf/aAAwDAQACEAMQAAAB6OtBGFa2/8QAGhABAAIDAQAAAAAAAAAAAAAAAQACAxESE//aAAgBAQABBQJyW7vkSe1iaNoIBU//xAAWEQEBAQAAAAAAAAAAAAAAAAAAEQH/2gAIAQMBAT8Bia//xAAZEQABBQAAAAAAAAAAAAAAAAAAAQIRElH/2gAIAQIBAT8BlCzcP//EABoQAAMBAAMAAAAAAAAAAAAAAAABESESMUH/2gAIAQEABj8CU6MU30k5FhGRKH//xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhQTFRYf/aAAgBAQABPyHjwtkhQI2lwNVg2E1C5WkTplYQ8n//2gAMAwEAAgADAAAAEAjv/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQAhYf/aAAgBAwEBPxAQO3S//8QAFxEBAQEBAAAAAAAAAAAAAAAAAQARIf/aAAgBAgEBPxDsOTD/xAAaEAEBAQADAQAAAAAAAAAAAAABEQAhMUFx/9oACAEBAAE/EEhJlEVOtxTFYSS051ExT5vZ7lQoemZMl9hTc8RsE3//2Q==","sizes":"(max-width: 750px) 100vw, 750px","src":"/static/6dc1a1b98e66073dbd7e7471a7fff24c/9f583/dockerswarm-vs-kubernetes.jpg","srcSet":"/static/6dc1a1b98e66073dbd7e7471a7fff24c/9f583/dockerswarm-vs-kubernetes.jpg 750w"}}},"author":{"id":"ludo","bio":"Développeur senior. Fullstack + DevOps","avatar":{"children":[{"fixed":{"src":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png"}}]}}},"fields":{"layout":"post","slug":"/dockerSwarm-vs-kubernetes/"}},"next":{"excerpt":"Dans cet article, vous apprendrez à créer et à gérer facilement des git hooks pour vos projets Node/NPM à l’aide de Husky. Git Hooks En termes simples, les git hooks sont des scripts personnalisés, qui peuvent être exécutés automatiquement lorsque des événements spécifiques se produisent. Des crochets (hooks) côté client sont déclenchés pour des actions telles que le commit ou le merge. Les crochets côté serveur s’exécutent dans des situations telles que la réception de données (git push) du client. Les hooks peuvent exécuter n’importe quelle logique personnalisée et, plus important encore, rejeter l’action effectuée si quelque chose ne va pas. Par exemple, vous pouvez annuler la validation du commit si son message ne contient pas l’ID de problème du suivi des problèmes. Vous pouvez également le refuser si l’analyse de code statique échoue. Cela peut être très utile si vous voulez vous assurer que votre base de code reste propre ou si vous souhaitez appliquer certaines règles de qualité. Mais comment pouvez-vous réellement installer et gérer ces hooks? Chaque fois que vous clonez un repo git, toutes les données git de votre projet sont stockées dans un répertoire .git dans votre dossier. Il contient plusieurs fichiers et sous-répertoires, l’un d’eux étant appelé \u001dhooks\u001d. À l’intérieur, vous trouverez un tas de fichiers.  Chacun d’entre eux est un script, qui est exécuté lorsqu’un événement spécifique se produit. Le nom de l’événement correspond au nom du fichier. Par exemple, la \u001dpre-commit\u001d est exécutée avant de commiter vos modifications. Comme vous pouvez le constater, tous les fichiers ont une extension \u001d.sample\u001d. Git ignore ces fichiers à moins que vous ne les renommiez. Vous devez supprimer l’extension \u001d.sample\u001d pour activer ces hooks. Dans les exemples de fichiers, vous pouvez trouver une description et un exemple d’implémentation que vous pouvez utiliser comme point de départ pour implémenter vos propres hooks. À quoi ça sert? Maintenant, regardons quelques exemples spécifiques de ce qui peut être réalisé avec les git hooks. Comme ce ne sont que des scripts, vous pouvez faire à peu près n’importe quoi. Habituellement, cela signifie effectuer divers contrôles de qualité. Vous pouvez vous assurer que l’utilisateur a son nom et son email renseignés. Vous pouvez vérifier que le message de validation est correctement formaté. Vous pouvez essayer de créer votre application et rejeter le commit si la construction échoue. Vous pouvez exécuter des tests pour vous assurer qu’ils passent avant le commit. L’utilisation typique est également l’analyse de code statique ou le formatage. Cela signifie qu’il faut vérifier dans votre code les problèmes courants, les mauvaises pratiques, les conventions de dénomination, etc. Il peut également être utile d’exécuter un outil tel que Prettier pour s’assurer que le code est bien formaté avant le commit. Cela évite de nombreux maux de tête lors de la révision du code. Vous pouvez même vérifier les failles de sécurité de votre code avec un outil tel que Snyk. Distribution aux membres de l’équipe Avec les hooks côté serveur, la distribution est facile. Vous n’avez généralement qu’un seul référentiel de serveur principal. Cela signifie que tous les membres de l’équipe mettent généralement leurs modifications au même endroit. Vous y installez vos hooks et vous avez terminé. Avec les hooks côté client, cela devient plus compliqué. Lorsque vous clonez un référentiel, les hooks ne sont pas transférés au client. Cela signifie qu’un référentiel fraîchement cloné n’a aucun hook, peu importe le type de hook que vous avez sur le serveur. Si vous voulez que les membres de votre équipe aient un ensemble unifié de git hooks, vous devez les distribuer d’une manière ou d’une autre et vous assurer qu’ils sont inclus dans leur sous-répertoire git hooks. La solution la plus élémentaire consiste à créer un emplacement partagé, où vous stockez vos hooks, puis demandez à vos développeurs de les télécharger et de les mettre dans leur répertoire de hooks. Bien sûr, vous ne pouvez pas être sûr qu’ils le feront réellement. Le problème est qu’ils ont besoin de savoir qu’ils devraient le faire et comment. Et même s’ils le font, ils peuvent être paresseux ou simplement ignorer votre politique. Vous pouvez améliorer un peu cette solution de base en ayant des hooks dans le référentiel de votre projet et en laissant simplement à vos développeurs exécuter un script personnalisé comme celui-ci, qui les copie ensuite dans leur répertoire de hooks. Sinon, git propose une option pour changer la destination du répertoire des hooks en un emplacement personnalisé: Ces solutions facilitent la distribution, mais ne résolvent pas les problèmes essentiels. Husky Installation Vous pouvez installer Husky simplement en exécutant: Alternative, avec yarn: Ajout de hooks Ajouter des hooks avec Husky est facile. Vous devez juste éditer votre package.json. Vous définissez quels scripts doivent être exécutés sur quel événement git. Pour Husky 1.0.0+, utilisez: Si vous utilisez une version de Husky antérieure à 1.0.0 (disponible dans la version candidate du 06/2018), la syntaxe est légèrement différente. Vous ajoutez vos hooks Husky directement dans la section scripts. L’exemple ci-dessus exécute tous vos tests avant de commiter et avant de pousser et si vos tests échouent, l’action git n’est pas exécutée. Bien sûr, vous pouvez exécuter tout autre script nom plutôt que le nom test. Problème de correction automatique avant validation Il est utile de casser le build si quelque chose ne va pas, mais il est encore plus utile de corriger automatiquement les problèmes avant de s’engager. Par exemple, vous pouvez personnaliser votre code en utilisant Prettier avant de faire un commit ou vous pouvez corriger automatiquement les problèmes de formatage, qui peuvent être résolus automatiquement. C’est beaucoup plus facile de cette façon. Heureusement, il existe un outil pour cela. Cela s’appelle lint-staged. Vous pouvez l’installer par: Maintenant, sur votre action de pre-commit, vous exécutez directement \u001dlint-staged\u001d au lieu de votre linter. Dans lint-staged, vous définissez ce qui doit être exécuté: Lorsque vous essayez de commiter maintenant, \u001dlint-staged\u001d peut modifier vos fichiers avant l’exécution de la validation. Cependant, ce qui est vraiment bien, c’est que vous ne filtrez que les fichiers en attente de validation, et non l’ensemble de votre projet. Cela signifie que l’ensemble du processus est beaucoup plus rapide. Bug JetBrains IDE La bonne nouvelle est que les git hooks configurés de cette manière sont exécutés non seulement lorsque vous utilisez git à partir de votre terminal, mais également à partir d’un IDE. La mauvaise nouvelle est que les IDE JetBrains (IDEA, Webstorm, …) ont actuellement un méchant bogue (voir IDEA-135454) et ne fonctionnent pas bien avec cette configuration. Le problème n’est pas résolu avant plusieurs années, mais heureusement, il existe une solution de contournement. Vous devez juste ajouter ce hook post-commit: Bien entendu, il ne s’agit que d’une solution de contournement jusqu’à ce que le problème soit résolu. Le suivi des problèmes de JetBrains contient une fonctionnalité de vote, alors assurez-vous de voter pour que ce problème soit résolu s’il vous pose problème. Intégration continue Une chose à noter est que Husky installe les hooks uniquement lorsqu’il ne s’exécute pas sur un serveur d’intégration continue. Husky peut détecter qu’il est en cours d’exécution dans le cadre d’un travail CI et n’installe aucun hook. En ignorant Les hooks côté client peuvent être utiles, mais vous ne pouvez pas trop compter sur eux. Ils ne sont que le premier niveau de défense. Vous ne pouvez pas être sûr à 100% qu’ils soient exécutés. Ils peuvent être ignorés à la demande en ajoutant une option de ligne de commande: Pour rendre les choses encore plus faciles, les hooks peuvent être désactivés à l’aide de certaines variables environnementales. Pour cette raison, il est toujours utile d’appliquer la même fonctionnalité sur le serveur. Performance Bien que les hooks cotés client tels que le pre-commit puissent s’avérer très utiles, vous devez garder à l’esprit qu’ils prennent un certain temps à s’exécuter. Les commits, qui sont généralement très rapides, car ils ne se produisent que sur le client, peuvent prendre soudainement très longtemps. Vous serez peut-être tenté d’exécuter tous les tests, l’analyse de code statique, les vérifications préalables, etc., avant chaque validation. Lorsqu’un commit prend des années, vos développeurs ne seront pas heureux et seront tentés d’ignorer les hooks lors de l’exécution de leurs commandes git. Vous devez donc trouver le bon équilibre entre ce qui doit être effectué sur le client et ce qui peut être un point d’accès côté serveur. Conclusion Husky est un outil utile qui permet de créer et de gérer facilement des hooks git sur le client. Vous n’avez plus besoin de distribuer vos hooks manuellement. Comme pour tout, gardez le nombre de hooks côté client avec modération afin d’éviter les temps d’exécution trop longs.","timeToRead":7,"frontmatter":{"title":"Git hooks avec Husky","subtitle":"En termes simples, les git hooks sont des scripts personnalisés, qui peuvent être exécutés automatiquement lorsque des événements spécifiques se produisent.","tags":["Git","Node.js","Javascript"],"category":["Git","Node.js"],"date":"2018-11-25T08:00:00.000Z","draft":false,"image":{"childImageSharp":{"fluid":{"aspectRatio":1.6103059581320451,"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQBAgMF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAL/2gAMAwEAAhADEAAAAeZvaUrjYf/EABkQAQADAQEAAAAAAAAAAAAAAAEAAiEREv/aAAgBAQABBQIrr2z4jDGf/8QAFhEBAQEAAAAAAAAAAAAAAAAAABIB/9oACAEDAQE/AZxL/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQIBAT8Bqv/EABkQAAIDAQAAAAAAAAAAAAAAAAAyASAxkf/aAAgBAQAGPwJTBZ7T/8QAGRAAAwEBAQAAAAAAAAAAAAAAAAERIUGh/9oACAEBAAE/IWy6ZuV4UVsOR8Kf/9oADAMBAAIAAwAAABDb7//EABcRAAMBAAAAAAAAAAAAAAAAAAABETH/2gAIAQMBAT8QbtIP/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/ELTT/8QAGxABAQEBAAMBAAAAAAAAAAAAAREAITFBUXH/2gAIAQEAAT8QEkQjOdxTGyQQ/nnNus/UZr6lPWsqdhrblLv/2Q==","sizes":"(max-width: 2000px) 100vw, 2000px","src":"/static/ac7733f363ac6c799dc4d94c21beb53b/883ab/husky2.jpg","srcSet":"/static/ac7733f363ac6c799dc4d94c21beb53b/f8f18/husky2.jpg 930w,\n/static/ac7733f363ac6c799dc4d94c21beb53b/0e6ff/husky2.jpg 1860w,\n/static/ac7733f363ac6c799dc4d94c21beb53b/883ab/husky2.jpg 2000w"}}},"author":{"id":"ludo","bio":"Développeur senior. Fullstack + DevOps","avatar":{"children":[{"fixed":{"src":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png"}}]}}},"fields":{"layout":"post","slug":"/git-husky/"}},"primaryTag":"Kindle","primaryCategory":"Kindle"}}}