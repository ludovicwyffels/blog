{"componentChunkName":"component---src-templates-post-tsx","path":"/k8s-minikube/","webpackCompilationHash":"ba1a271305926245155b","result":{"data":{"logo":{"childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAABFUlEQVQY023PvUrDUBTA8ZuCtoMoOLQ4dWhN14x2kEKXFkGoohQ/QBexOHRycAidKkgHHRq69APRoTjFJYODIA6+gSBYfYMmfYLE/5VT6NALP845NyeHc9UoCHZRQvonCLKKE4ZhAXYURTsYoE9dIy5iCzfUJnEdV+RF4iu6ikFH2EPxazzOcJmg4Rnn5C8ysIEOHqTe5/sT3qXOwYOtRr5/wLAqzpCTDXu4p2ETtyjgGJ/cX+se8jeU9fa4RBt5vWENpjzdkoGPcGg4RQsbOMEFmnBRRwVDHEK/yFXfvr/CoPjvZLKcdByDyzWGeajigzorGy0oOeRJiUtITe/pX1XzDk3buIMltSFR/zTtic3060X+8z8PsEUt8G3LVQAAAABJRU5ErkJggg==","width":400,"height":128,"src":"/static/2b5eaa0de166a8b5faebad4955c2200c/647de/ghost-logo.png","srcSet":"/static/2b5eaa0de166a8b5faebad4955c2200c/647de/ghost-logo.png 1x"}}},"markdownRemark":{"html":"<p><a href=\"https://kubernetes.io/docs/setup/minikube/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Minikube</a> est un outil idéal pour configuer localement <a href=\"https://kubernetes.io/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kubernetes</a> afin de tester et d’expérimenter vos déploiements.</p>\n<p>Dans ce guide, je vais essayer de vous aider à le mettre en marche sur votre machine locale, à donner quelques conseils sur où et comment effectuer certaines tâches et à le rendre aussi capable (je suppose quand vous utilisez k8s que vous veulent apprendre et utiliser Helm, etcd, istio, etc.).</p>\n<h1>Installation de minikube</h1>\n<p>Minikube fonctionne avec une machine virtuelle. Pour cela, on peut utiliser diverses options en fonction de vos préférences et de votre système d’exploitation. Ma préférence dans ce cas est Orable <a href=\"https://www.virtualbox.org/wiki/Downloads\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">VirtualBox</a>.</p>\n<p>Vous pouvez utiliser <strong>brew</strong> pour tout installer:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">brew cask <span class=\"token function\">install</span> virtualbox minikube</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Dans ce cas, vous pourriez obtenir une erreur d’installation peu concluante liée à l’installation de virtualbox, en particulier sur Mojave et problablement par la suite.</p>\n<p>Quoi qu’il en soit, il s’agit problablement d’une nouvelle fonctionnalité de sécurité dans MacOs X qui vous gêne.</p>\n<p>Allez dans <strong>Préférences Système> Sécurité et confidentialité</strong> et sur l’écran <strong>Général</strong>, vous verrez un (ou quelques) messages concernant certains logiciels nécessitant une approbation pour être installés. Vous devez examiner attentivement la liste s’il en existe plusieurs et autoriser l’installation du logiciel dont vous avez besoin - dans ce cas, le logiciel <strong>Oracle</strong>.</p>\n<p>Cela fait, vous pourrez relancer la commande ci-dessus et vous devrez alors être prêt pour les étapes suivantes.</p>\n<h1>Exécuter et accéder au cluster</h1>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">minikube start</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Afin d’utiliser de manière optimale les ressources de votre ordinateur local, je suggérerais de l’arrêter quand vous n’en avez plus besoin… Avec VirtualBox au centre, il utilisera la batterie de votre ordinateur portable assez rapidement. Recommencer plus tard vous ramènera là où vous l’avez laissé:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">minikube stop</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Le tableau de bord Kubernetes est également disponible (lorsque minikube est en cours d’exécution):</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">minikube dashboard</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Je vais supposer que vous avez kubectl installé localement et que vous l’utilisez déjà pour certains clusters distants, vous disposez donc de plusieurs contextes. Dans ce cas, vous devez répertorier les contextes et passer à minikube.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">kubectl config get-contexts\nkubectl config use-context minikube</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<p>Vous vous trouvez maintenant dans le contexte de votre cluster k8 local qui s’exécute sur minikube et vous pouvez effectuer toutes les opérations k8 qu’il contient.</p>\n<h1>Ingress</h1>\n<p>Pour exécuter vos déploiements comportant un ingress, vous aurez besoin d’un add-on d’entrée:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">minikube addons <span class=\"token builtin class-name\">enable</span> ingress</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Assurez-vous que vous configurez l’ingress en fonction de vos hôtes locaux. Cela signifie fondamentalement que tout ce que vous définissez comme hôte dans vos règles d’ingress doit être configuré dans votre fichier /etc/hosts</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-text line-numbers\"><code class=\"language-text\">[minikube ip] your.host</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Où <code>[minikube ip]</code> devrait être remplacé par l’ip actuel de minikube. Il fonctionne également avec plusieurs hôtes locaux séparés par des espaces après l’adresse ip de minikube.</p>\n<p>Voici un raccourci pour le faire en bash</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\"><span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"<span class=\"token variable\"><span class=\"token variable\">$(</span>minikube <span class=\"token function\">ip</span><span class=\"token variable\">)</span></span> local.host\"</span> <span class=\"token operator\">|</span> <span class=\"token function\">sudo</span> <span class=\"token function\">tee</span> -a /etc/hosts</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<h1>Docker registry</h1>\n<blockquote>\n<p>La réalité de l’utilisation réelle du registre de conteneurs dans l’environnement local est rude. Je vais donc vous fournir une option simple, rapide et simpliste qui facilite le déploiement de votre travail local sur vos k8s locaux, mais vous prive de l’expérience très importante du registre de conteneurs.</p>\n</blockquote>\n<h2>Registre de conteneurs local</h2>\n<p>Obtenez le contexte de votre docker local pour pointer vers le context minikube: </p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\"><span class=\"token builtin class-name\">eval</span> <span class=\"token variable\"><span class=\"token variable\">$(</span>minikube docker-env<span class=\"token variable\">)</span></span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Dans le contexte minikube, pour démarrer le registre docker local</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">docker run -d -p <span class=\"token number\">5000</span>:5000 --restart<span class=\"token operator\">=</span>always --name registry registry:2</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>Donc, vous avez maintenant un registre local dans lequel pousser des choses (tant que votre docker est dans le contexte minikube)</p>\n<p>Vous pouvez maintenant faire:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">docker build <span class=\"token builtin class-name\">.</span> -t <span class=\"token operator\">&lt;</span>your_tag<span class=\"token operator\">></span>\ndocker tag <span class=\"token operator\">&lt;</span>your_tag<span class=\"token operator\">></span> localhost:5000/<span class=\"token operator\">&lt;</span>your_tag<span class=\"token operator\">></span>:<span class=\"token operator\">&lt;</span>version<span class=\"token operator\">></span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<p>A ce stade, vous pouvez utiliser <code>localhost:5000/&#x3C;your_tag></code>: comme image dans votre déploiement et c’est tout.</p>\n<h2>Utilisation du référentiel de conteneur distant</h2>\n<p>Pour utiliser localement le référentiel de conteneur distant, vous devez fournir un moyen d’authentification, qui se base sur les <a href=\"https://kubernetes.io/docs/concepts/configuration/secret/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">secrets</a> de Kubernetes.</p>\n<p>Pour la gestion des secrets locaux pour ECR, GCR and Docker registry, je recommande d’utiliser l’addon minikube appelé <a href=\"https://github.com/upmc-enterprises/registry-creds\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">registry-creds</a>. Je ne le considère pas suffisamment sûr pour être utilisé ailleurs que dans l’environnement local.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">minikube addons configure registry-creds\nminikube addons <span class=\"token builtin class-name\">enable</span> registry-creds</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<h1>Helm</h1>\n<p>Helm est un gestionnaire de paquets pour k8s et est souvent utilisé pour la gestion de la configuration d’un déploiement à l’autre. Compte tenu de la grande popularité de l’outil et de son adoption croissante, je voudrais terminer ce guide par une note sur l’ajout de helm à votre environnement Kubernetes local.</p>\n<p>C’est assez facile à ce stade, il suffit de mettre en place minikube et:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-bash line-numbers\"><code class=\"language-bash\">brew <span class=\"token function\">install</span> kubernetes-helm\nhelm init</code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span></span></pre></div>\n<blockquote>\n<p>Helm utilise un backend appelé <strong>Tiller</strong>. C’est ce qui est installé/déployé lors de l’exécution de <code>helm init</code>.</p>\n</blockquote>\n<p>Une lecture précieuse: <a href=\"https://helm.sh/docs/using_helm/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://helm.sh/docs/using_helm/</a></p>\n<p>Maintenant, vous disposez d’un environnement Kubernetes local complet capable d’accepter tous vos déploiements de test avant de décider de les placer dans le cloud.</p>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://kubernetes.io/docs/setup/minikube/","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"text","value":"Minikube"}]},{"type":"text","value":" est un outil idéal pour configuer localement "},{"type":"element","tagName":"a","properties":{"href":"https://kubernetes.io/","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"text","value":"Kubernetes"}]},{"type":"text","value":" afin de tester et d’expérimenter vos déploiements."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Dans ce guide, je vais essayer de vous aider à le mettre en marche sur votre machine locale, à donner quelques conseils sur où et comment effectuer certaines tâches et à le rendre aussi capable (je suppose quand vous utilisez k8s que vous veulent apprendre et utiliser Helm, etcd, istio, etc.)."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Installation de minikube"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Minikube fonctionne avec une machine virtuelle. Pour cela, on peut utiliser diverses options en fonction de vos préférences et de votre système d’exploitation. Ma préférence dans ce cas est Orable "},{"type":"element","tagName":"a","properties":{"href":"https://www.virtualbox.org/wiki/Downloads","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"text","value":"VirtualBox"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Vous pouvez utiliser "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"brew"}]},{"type":"text","value":" pour tout installer:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"brew cask "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"install"}]},{"type":"text","value":" virtualbox minikube"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Dans ce cas, vous pourriez obtenir une erreur d’installation peu concluante liée à l’installation de virtualbox, en particulier sur Mojave et problablement par la suite."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Quoi qu’il en soit, il s’agit problablement d’une nouvelle fonctionnalité de sécurité dans MacOs X qui vous gêne."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Allez dans "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Préférences Système> Sécurité et confidentialité"}]},{"type":"text","value":" et sur l’écran "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Général"}]},{"type":"text","value":", vous verrez un (ou quelques) messages concernant certains logiciels nécessitant une approbation pour être installés. Vous devez examiner attentivement la liste s’il en existe plusieurs et autoriser l’installation du logiciel dont vous avez besoin - dans ce cas, le logiciel "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Oracle"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Cela fait, vous pourrez relancer la commande ci-dessus et vous devrez alors être prêt pour les étapes suivantes."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Exécuter et accéder au cluster"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"minikube start"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Afin d’utiliser de manière optimale les ressources de votre ordinateur local, je suggérerais de l’arrêter quand vous n’en avez plus besoin… Avec VirtualBox au centre, il utilisera la batterie de votre ordinateur portable assez rapidement. Recommencer plus tard vous ramènera là où vous l’avez laissé:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"minikube stop"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Le tableau de bord Kubernetes est également disponible (lorsque minikube est en cours d’exécution):"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"minikube dashboard"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Je vais supposer que vous avez kubectl installé localement et que vous l’utilisez déjà pour certains clusters distants, vous disposez donc de plusieurs contextes. Dans ce cas, vous devez répertorier les contextes et passer à minikube."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"kubectl config get-contexts\nkubectl config use-context minikube"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]},{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Vous vous trouvez maintenant dans le contexte de votre cluster k8 local qui s’exécute sur minikube et vous pouvez effectuer toutes les opérations k8 qu’il contient."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Ingress"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour exécuter vos déploiements comportant un ingress, vous aurez besoin d’un add-on d’entrée:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"minikube addons "},{"type":"element","tagName":"span","properties":{"className":["token","builtin","class-name"]},"children":[{"type":"text","value":"enable"}]},{"type":"text","value":" ingress"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Assurez-vous que vous configurez l’ingress en fonction de vos hôtes locaux. Cela signifie fondamentalement que tout ce que vous définissez comme hôte dans vos règles d’ingress doit être configuré dans votre fichier /etc/hosts"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-text","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"[minikube ip] your.host"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Où "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"[minikube ip]"}]},{"type":"text","value":" devrait être remplacé par l’ip actuel de minikube. Il fonctionne également avec plusieurs hôtes locaux séparés par des espaces après l’adresse ip de minikube."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Voici un raccourci pour le faire en bash"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"element","tagName":"span","properties":{"className":["token","builtin","class-name"]},"children":[{"type":"text","value":"echo"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","string"]},"children":[{"type":"text","value":"\""},{"type":"element","tagName":"span","properties":{"className":["token","variable"]},"children":[{"type":"element","tagName":"span","properties":{"className":["token","variable"]},"children":[{"type":"text","value":"$("}]},{"type":"text","value":"minikube "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"ip"}]},{"type":"element","tagName":"span","properties":{"className":["token","variable"]},"children":[{"type":"text","value":")"}]}]},{"type":"text","value":" local.host\""}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"|"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"sudo"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"tee"}]},{"type":"text","value":" -a /etc/hosts"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Docker registry"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"La réalité de l’utilisation réelle du registre de conteneurs dans l’environnement local est rude. Je vais donc vous fournir une option simple, rapide et simpliste qui facilite le déploiement de votre travail local sur vos k8s locaux, mais vous prive de l’expérience très importante du registre de conteneurs."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Registre de conteneurs local"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Obtenez le contexte de votre docker local pour pointer vers le context minikube: "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"element","tagName":"span","properties":{"className":["token","builtin","class-name"]},"children":[{"type":"text","value":"eval"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","variable"]},"children":[{"type":"element","tagName":"span","properties":{"className":["token","variable"]},"children":[{"type":"text","value":"$("}]},{"type":"text","value":"minikube docker-env"},{"type":"element","tagName":"span","properties":{"className":["token","variable"]},"children":[{"type":"text","value":")"}]}]}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Dans le contexte minikube, pour démarrer le registre docker local"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"docker run -d -p "},{"type":"element","tagName":"span","properties":{"className":["token","number"]},"children":[{"type":"text","value":"5000"}]},{"type":"text","value":":5000 --restart"},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"="}]},{"type":"text","value":"always --name registry registry:2"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Donc, vous avez maintenant un registre local dans lequel pousser des choses (tant que votre docker est dans le contexte minikube)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Vous pouvez maintenant faire:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"docker build "},{"type":"element","tagName":"span","properties":{"className":["token","builtin","class-name"]},"children":[{"type":"text","value":"."}]},{"type":"text","value":" -t "},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"<"}]},{"type":"text","value":"your_tag"},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":">"}]},{"type":"text","value":"\ndocker tag "},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"<"}]},{"type":"text","value":"your_tag"},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":">"}]},{"type":"text","value":" localhost:5000/"},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"<"}]},{"type":"text","value":"your_tag"},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":">"}]},{"type":"text","value":":"},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"<"}]},{"type":"text","value":"version"},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":">"}]}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]},{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"A ce stade, vous pouvez utiliser "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"localhost:5000/<your_tag>"}]},{"type":"text","value":": comme image dans votre déploiement et c’est tout."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Utilisation du référentiel de conteneur distant"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour utiliser localement le référentiel de conteneur distant, vous devez fournir un moyen d’authentification, qui se base sur les "},{"type":"element","tagName":"a","properties":{"href":"https://kubernetes.io/docs/concepts/configuration/secret/","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"text","value":"secrets"}]},{"type":"text","value":" de Kubernetes."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour la gestion des secrets locaux pour ECR, GCR and Docker registry, je recommande d’utiliser l’addon minikube appelé "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/upmc-enterprises/registry-creds","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"text","value":"registry-creds"}]},{"type":"text","value":". Je ne le considère pas suffisamment sûr pour être utilisé ailleurs que dans l’environnement local."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"minikube addons configure registry-creds\nminikube addons "},{"type":"element","tagName":"span","properties":{"className":["token","builtin","class-name"]},"children":[{"type":"text","value":"enable"}]},{"type":"text","value":" registry-creds"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]},{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Helm"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Helm est un gestionnaire de paquets pour k8s et est souvent utilisé pour la gestion de la configuration d’un déploiement à l’autre. Compte tenu de la grande popularité de l’outil et de son adoption croissante, je voudrais terminer ce guide par une note sur l’ajout de helm à votre environnement Kubernetes local."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"C’est assez facile à ce stade, il suffit de mettre en place minikube et:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"style":"counter-reset: linenumber NaN","className":["language-bash","line-numbers"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"brew "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"install"}]},{"type":"text","value":" kubernetes-helm\nhelm init"}]},{"type":"element","tagName":"span","properties":{"ariaHidden":"true","className":["line-numbers-rows"],"style":"white-space: normal; width: auto; left: 0;"},"children":[{"type":"element","tagName":"span","properties":{},"children":[]},{"type":"element","tagName":"span","properties":{},"children":[]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Helm utilise un backend appelé "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"Tiller"}]},{"type":"text","value":". C’est ce qui est installé/déployé lors de l’exécution de "},{"type":"element","tagName":"code","properties":{},"children":[{"type":"text","value":"helm init"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Une lecture précieuse: "},{"type":"element","tagName":"a","properties":{"href":"https://helm.sh/docs/using_helm/","target":"_blank","rel":["nofollow","noopener","noreferrer"]},"children":[{"type":"text","value":"https://helm.sh/docs/using_helm/"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Maintenant, vous disposez d’un environnement Kubernetes local complet capable d’accepter tous vos déploiements de test avant de décider de les placer dans le cloud."}]}],"data":{"quirksMode":false}},"excerpt":"Minikube est un outil idéal pour configuer localement Kubernetes afin de tester et d’expérimenter vos déploiements. Dans ce guide, je vais essayer de vous aider à le mettre en marche sur votre machine locale, à donner quelques conseils sur où et comment effectuer certaines tâches et à le rendre aussi capable (je suppose quand vous utilisez k8s que vous veulent apprendre et utiliser Helm, etcd, istio, etc.). Installation de minikube Minikube fonctionne avec une machine virtuelle. Pour cela, on peut utiliser diverses options en fonction de vos préférences et de votre système d’exploitation. Ma préférence dans ce cas est Orable VirtualBox. Vous pouvez utiliser brew pour tout installer: Dans ce cas, vous pourriez obtenir une erreur d’installation peu concluante liée à l’installation de virtualbox, en particulier sur Mojave et problablement par la suite. Quoi qu’il en soit, il s’agit problablement d’une nouvelle fonctionnalité de sécurité dans MacOs X qui vous gêne. Allez dans Préférences Système> Sécurité et confidentialité et sur l’écran Général, vous verrez un (ou quelques) messages concernant certains logiciels nécessitant une approbation pour être installés. Vous devez examiner attentivement la liste s’il en existe plusieurs et autoriser l’installation du logiciel dont vous avez besoin - dans ce cas, le logiciel Oracle. Cela fait, vous pourrez relancer la commande ci-dessus et vous devrez alors être prêt pour les étapes suivantes. Exécuter et accéder au cluster Afin d’utiliser de manière optimale les ressources de votre ordinateur local, je suggérerais de l’arrêter quand vous n’en avez plus besoin… Avec VirtualBox au centre, il utilisera la batterie de votre ordinateur portable assez rapidement. Recommencer plus tard vous ramènera là où vous l’avez laissé: Le tableau de bord Kubernetes est également disponible (lorsque minikube est en cours d’exécution): Je vais supposer que vous avez kubectl installé localement et que vous l’utilisez déjà pour certains clusters distants, vous disposez donc de plusieurs contextes. Dans ce cas, vous devez répertorier les contextes et passer à minikube. Vous vous trouvez maintenant dans le contexte de votre cluster k8 local qui s’exécute sur minikube et vous pouvez effectuer toutes les opérations k8 qu’il contient. Ingress Pour exécuter vos déploiements comportant un ingress, vous aurez besoin d’un add-on d’entrée: Assurez-vous que vous configurez l’ingress en fonction de vos hôtes locaux. Cela signifie fondamentalement que tout ce que vous définissez comme hôte dans vos règles d’ingress doit être configuré dans votre fichier /etc/hosts Où [minikube ip] devrait être remplacé par l’ip actuel de minikube. Il fonctionne également avec plusieurs hôtes locaux séparés par des espaces après l’adresse ip de minikube. Voici un raccourci pour le faire en bash Docker registry La réalité de l’utilisation réelle du registre de conteneurs dans l’environnement local est rude. Je vais donc vous fournir une option simple, rapide et simpliste qui facilite le déploiement de votre travail local sur vos k8s locaux, mais vous prive de l’expérience très importante du registre de conteneurs. Registre de conteneurs local Obtenez le contexte de votre docker local pour pointer vers le context minikube:  Dans le contexte minikube, pour démarrer le registre docker local Donc, vous avez maintenant un registre local dans lequel pousser des choses (tant que votre docker est dans le contexte minikube) Vous pouvez maintenant faire: A ce stade, vous pouvez utiliser localhost:5000/<your_tag>: comme image dans votre déploiement et c’est tout. Utilisation du référentiel de conteneur distant Pour utiliser localement le référentiel de conteneur distant, vous devez fournir un moyen d’authentification, qui se base sur les secrets de Kubernetes. Pour la gestion des secrets locaux pour ECR, GCR and Docker registry, je recommande d’utiliser l’addon minikube appelé registry-creds. Je ne le considère pas suffisamment sûr pour être utilisé ailleurs que dans l’environnement local. Helm Helm est un gestionnaire de paquets pour k8s et est souvent utilisé pour la gestion de la configuration d’un déploiement à l’autre. Compte tenu de la grande popularité de l’outil et de son adoption croissante, je voudrais terminer ce guide par une note sur l’ajout de helm à votre environnement Kubernetes local. C’est assez facile à ce stade, il suffit de mettre en place minikube et: Helm utilise un backend appelé Tiller. C’est ce qui est installé/déployé lors de l’exécution de helm init. Une lecture précieuse: https://helm.sh/docs/using_helm/ Maintenant, vous disposez d’un environnement Kubernetes local complet capable d’accepter tous vos déploiements de test avant de décider de les placer dans le cloud.","timeToRead":4,"frontmatter":{"title":"Configuration locale de Kubernetes avec minikube sur MacOS X","subtitle":"","userDate":"23 May 2019","date":"2019-05-23T08:00:00.000Z","tags":["Kubernetes","DevOps"],"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIFA//EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHN5DxbJYf/xAAaEAACAgMAAAAAAAAAAAAAAAAAAQIDEBET/9oACAEBAAEFAlaRsOmEbZ//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAYEAACAwAAAAAAAAAAAAAAAAAAMgEgMf/aAAgBAQAGPwJhpNp//8QAGhAAAwEAAwAAAAAAAAAAAAAAAAERITFhgf/aAAgBAQABPyHSUvSOU7FgtjtClyf/2gAMAwEAAgADAAAAEGQv/8QAFhEBAQEAAAAAAAAAAAAAAAAAABFB/9oACAEDAQE/EMV//8QAFREBAQAAAAAAAAAAAAAAAAAAEEH/2gAIAQIBAT8Qp//EABoQAQEAAwEBAAAAAAAAAAAAAAEAESExUZH/2gAIAQEAAT8QTFAXqtS5LFXZken2T1hAFInS/9k=","aspectRatio":1.7809439002671417,"src":"/static/aac12d8124ce6730c0247f5495bff894/883ab/ship.jpg","srcSet":"/static/aac12d8124ce6730c0247f5495bff894/f8f18/ship.jpg 930w,\n/static/aac12d8124ce6730c0247f5495bff894/0e6ff/ship.jpg 1860w,\n/static/aac12d8124ce6730c0247f5495bff894/883ab/ship.jpg 2000w","sizes":"(max-width: 2000px) 100vw, 2000px"}}},"author":{"id":"ludo","name":"Wyffels Ludovic","bio":"Développeur senior. Fullstack + DevOps","avatar":{"children":[{"__typename":"ImageSharp","fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAABMUlEQVQ4y2MwsXf5T03MMGogGBvbOYNpUwdXOIbJwdgwNQQNhCk0snX6r2thC8Y6QGxg7QCWA/FBcrgMxepCkAZrV6//EYmpYBydkvHfMzjiv5mj2//whJT/Nm7ecEMJGgjykp6V/f+AqLj/O/Ye+L8diA8dO/m/pbv/v72n3/+tu/f9D45N/K9naYcSFESFoRXQlSCX2rh7g/kgr1u5epIWhiAMCi/3wLD/fVNn/u+fNgtMT5g+6//kmXOB/Jn/PYLCwWrINnDijDlAPBvKJ8NAZC+DIgCkGYRBbJAYSV5GjpTte/b/PwiMkLj0nP8xqVn/Dxw9AY6kwOh40iIFlmzCgUkmKjnjvx0wdu08fMFskJi1mxfxyQY9YetAEzJyQic5YaNnPeTgIDnrjZaHJGMACtTMXoVAJ6sAAAAASUVORK5CYII=","width":400,"height":400,"src":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png","srcSet":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png 1x"}}]}}}},"relatedPosts":{"totalCount":3,"edges":[{"node":{"id":"b7646ada-6f35-5115-83e5-3a326c8cd1ea","timeToRead":16,"excerpt":"J’ai installé Docker Swarm et Kubernetes sur deux machines virtuelles. J’ai trouvé que Docker Swarm est très facile à installer et à configurer, alors que Kubernetes est un peu plus difficile à installer mais reste simple à utiliser. Introduction Cela fait des années que je veux essayer des conteneurs: la configuration manuelle de serveurs prend du temps, n’est pas reproductible et risque d’introduire des différences entre mon environnement de test local et la production. Les containers offrent une solution à tous ces problèmes et facilite beaucoup l’exécution d’instances supplémentaires d’une application. Cela peut rendre un service plus évolutif. Pour exécuter un service évolutif, vous avez besoin d’un moteur Container Orchestration qui répartit la charge en exécutant des conteneurs sur plusieurs ordinateurs et en envoyant des demandes à chaque instance de l’application. Docker Swarm et Kubernetes sont deux moteurs d’orchestration populaires. J’ai décidé d’essayer les deux en déployant la même application avec chaque moteur. Création du conteneur J’ai décidé d’utiliser Samba pour l’application de test. Samba est un serveur de fichiers populaire permettant aux ordinateurs Linux de partager des fichiers avec des ordinateurs Windows. Il communique via TCP sur le port 445. C’est la première fois que je travaille avec Docker, j’ai donc modifié un conteneur Samba standard afin d’inclure le fichier que je voulais servir. Après le tutoriel de Docker, j’ai lancé manuellement le conteneur à partir de la ligne de commande pour vérifier son fonctionnement: Et en effet, j’ai pu me connecter au serveur Samba dans le conteneur avec smbclient Maintenant que je sais que le conteneur fonctionne, je peux l’utiliser dans un moteur d’orchestration de conteneur. Préparer les machines virtuelles J’ai créé deux machines virtuelles exécutant Ubuntu 18.04 dans VirtualBox. J’ai ajouté une carte réseau supplémentaire à chaque machine virtuelle, configurée pour le réseau interne afin qu’ils puissent se parler: https://cdn-images-1.medium.com/max/1600/1*chCjRdcU_mV9ioAyQ7oB5A.png Ensuite, j’ai ajouté un serveur DHCP pour attribuer des adresses IP à chaque machine virtuelle: Les machines virtuelles peuvent désormais communiquer entre elles. Cela donne à ma machine virtuelle principale l’adresse IP 10.133.7.100. Docker Swarm Docker Swarm est un moteur d’orchestration de conteneur intégré à Docker lui-même. Quand je l’ai trouvé, j’étais sceptique: pourquoi l’utiliser à la place des Kubernetes, beaucoup plus célèbres? La réponse: Docker Swarm est axé sur la simplicité par rapport à la configuration. Cela ressemblait à l’iOS des moteurs d’orchestration de conteneurs par rapport à l’Android de Kubernetes. Mise en place de Docker Swarm Docker Swarm est facile à installer: il suffit d’installer Docker et docker-compose. Ensuite, après le tutoriel officiel, j’ai exécuté la seule commande nécessaire pour démarrer le noeud du gestionnaire, en transmettant l’adresse IP de la machine virtuelle actuelle: C’est tout: le moteur Docker tourne maintenant en mode Swarm. Ensuite, j’ai déployé un registre privé Docker afin que les autres noeuds puissent extraire des images, en suivant à nouveau les instructions d’installation: Déploiement de l’application Docker Swarm utilise le format Docker Compose pour spécifier les conteneurs à exécuter et les ports qu’ils exportent. Après le didacticiel Docker Compose, j’ai créé ce manifeste Docker Compose: Cela indique à Docker Compose de créer le fichier Docker à partir du répertoire «sambaonly», d’upload/pull les conteneurs construits vers mon registre privé nouvellement configuré et d’exporter le port 445 à partir du conteneur. Pour déployer ce manifeste, j’ai suivi le tutoriel de Docker Swarm. J’ai d’abord utilisé Docker Compose pour créer et télécharger le conteneur dans le registre privé: Une fois le conteneur créé, l’application peut être déployée avec la commande docker stack deploy, en spécifiant le nom du service: Et maintenant, l’application fonctionne sous Samba Swarm. J’ai testé qu’il fonctionne toujours avec smbclient: Ajout d’un autre noeud Ici encore, la simplicité de Docker Swarm transparaît. Pour installer un deuxième noeud, j’ai d’abord installé Docker, puis exécuté la commande que Docker m’avait donnée lors de l’installation de swarm: Pour exécuter mon application sur les deux nœuds, j’ai exécuté la commande scale de Docker Swarm sur le nœud du gestionnaire: Sur le nouveau noeud de travail, le nouveau conteneur est apparu: Test de l’équilibrage de charge (load balancing) Docker Swarm comprend un load balancing intégré appelé routeur Mesh: les demandes adressées à l’adresse IP de tout noeud sont automatiquement réparties sur l’ensemble de Swarm. Pour tester cela, j’ai établi 1000 connexions à l’adresse IP du noeud du gestionnaire avec nc: Samba génère un nouveau processus pour chaque connexion. Par conséquent, si l’équilibrage de la charge fonctionne, je m’attendrais à environ 500 processus Samba sur chaque noeud de Swarm. C’est bien ce qui se passe. Après avoir exécuté le script pour établir 1000 connexions, j’ai vérifié le nombre de processus Samba sur le gestionnaire (10.133.7.100): Et sur le noeud travailleur (10.133.7.50): Ainsi, exactement la moitié des demandes adressées au noeud de gestion ont été redirigées de manière magique vers le premier noeud de travail, ce qui montre que le cluster Swarm fonctionne correctement. J’ai trouvé que Docker Swarm était très facile à installer et il fonctionnait bien sous une charge (légère). Kubernetes Kubernetes est en train de devenir l’industrie standard de l’orchestration de conteneurs. C’est beaucoup plus flexible que Docker Swarm, mais cela rend plus difficile la configuration. Je l’ai trouvé pas si difficile, cependant. Pour cette expérience, au lieu d’utiliser un environnement de développement Kubernetes pré-construit tel que minikube, j’ai décidé de configurer mon propre cluster, à l’aide de Kubadm, WeaveNet et MetalLB. Mise en place de Kubernetes Kubernetes à la réputation d’être difficile à configurer: vous avez entendu le processus complexe en plusieurs étapes du didacticiel Kubernetes the Hard Way Les développeurs de Kubernetes ont simplifié l’utilisation de kubeadm. Malheureusement, Kubernetes étant si flexible, le tutoriel sur kubeadm ne couvre pas encore quelques étapes. J’ai donc dû déterminer le réseau et l’équilibreur de charge à utiliser moi-même. Voici ce que j’ai fini par lancer. J’ai d’abord dû désactiver Swap sur chaque noeud: Ensuite, j’ai configuré le noeud maître (10.133.7.100) avec la commande suivante: L’option --pod-network-cidr attribue une adresse réseau interne à tous les noeuds du réseau, utilisée pour les communications internes dans Kubernetes. Les options --apiserver-advertise-address et --apiserver-cert-extra-sans ont été ajoutées à cause d’un problème particulier dans l’installation de VirtualBox: la carte virtuelle principale des machines virtuelles (IP 10.0.2.15) ne peut accéder qu’à l’Internet. J’ai dû préciser que d’autres noeuds doivent accéder au maître à l’aide de l’adresse IP 10.133.7.100. Après avoir exécuté cette commande, Kubeadm a affiché quelques instructions: J’ai raté ces instructions la première fois et je n’ai donc pas terminé la configuration. J’ai ensuite passé une semaine entière à me demander pourquoi aucun de mes conteneurs ne fonctionnait! Après avoir enfin lu les instructions, je devais faire trois autres choses: Tout d’abord, je devais exécuter les commandes données par kubeadm pour configurer un fichier de configuration. Par défaut, Kubernetes ne planifie pas les conteneurs sur le nœud maître, mais uniquement sur les noeuds de travail. Comme je n’ai qu’un seul noeud pour le moment, le tutoriel m’a montré cette commande pour autoriser l’exécution de conteneurs sur le seul noeud: Enfin, je devais choisir un réseau pour mon cluster. Installation du réseau Contrairement à Docker Swarm, qui doit utiliser sa propre couche de routage maillé pour la mise en réseau et l’équilibrage de la charge, Kubernetes offre de multiples choix pour la mise en réseau et l’équilibrage de la charge. Le composant de mise en réseau permet aux conteneurs de communiquer en interne. J’ai fait des recherches et cet article comparatif suggérait Flannel ou WeaveNet, car ils sont faciles à configurer. Ainsi, j’ai décidé d’essayer WeaveNet. J’ai suivi les instructions du didacticiel kubeadm pour appliquer la configuration de WeaveNet: Ensuite, pour permettre aux conteneurs de communiquer avec le monde extérieur, j’ai besoin d’un équilibreur de charge. D’après mes recherches, j’ai eu l’impression que la plupart des implémentations de l’équilibreur de charge Kubernetes se concentrent uniquement sur les services HTTP, et non sur le TCP brut. Heureusement, j’ai trouvé MetalLB, un projet récent (vieux d’un an) qui comble cette lacune. Pour installer MetalLB, j’ai suivi son didacticiel de mise en route et j’ai tout d’abord déployé MetalLB: Ensuite, j’ai attribué la plage d’adresses IP 10.133.7.200 à 10.133.7.230 à MetalLB, en créant et en appliquant ce fichier de configuration: Déploiement de l’application Les fichiers de configuration du service de Kubernetes sont plus détaillés que ceux de Docker Swarm, en raison de la flexibilité de Kubernetes. En plus de spécifier le conteneur à exécuter, comme Docker Swarm, je dois spécifier comment chaque port doit être traité. Après avoir lu le tutoriel de Kubernetes, j’ai proposé cette configuration de Kubernetes, composée d’un service et d’un déploiement. https://gist.github.com/ludovicwyffels/911bb25b611f3519745aeee0d53c6447 Ce service demande à Kubernetes d’exporter le port TCP 445 de nos conteneurs Samba vers l’équilibreur de charge. https://gist.github.com/ludovicwyffels/41022da159c539e45027c68776f459d8 Cet objet Deployment indique à Kubernetes d’exécuter mon conteneur et d’exporter un port que le service doit gérer. Notez le replicas: 1 - c’est le nombre d’instances du conteneur que je veux exécuter. Je peux déployer ce service sur Kubernetes en utilisant kubectl apply: Et, après avoir redémarré ma machine virtuelle à quelque reprises, le déploiement a finalement commencé à fonctionner: Mon service est maintenant disponible sur l’adresse IP externe attribuée par MetalLB: Ajout d’un autre noeud Ajouter un autre noeud dans un cluster Kubernetes est beaucoup plus simple: il me suffisait d’exécuter la commande donnée par kubeadm sur le nouvel ordinateur: Bizarreries de ma configuration J’ai dû faire deux changements en raison de la configuration de VirtualBox: Premièrement, comme ma machine virtuelle dispose de deux cartes réseau, je dois indiquer manuellement l’adresse IP de ma machine à Kubernetes. Selon ce problème, je devais éditer Et changer une ligne en avant de redémarrer Kubernetes: L’autre solution concerne le registre Docker: comme le nouveau noeud ne peut accéder à mon registre privé sur le noeud maître, j’ai décidé de procéder à un terrible hack et de partager le registre de mon noeud maître vers la nouvelle machine à l’aide de ssh: Cela transmet le port 5000 du noeud principal, dora (qui exécute le registre Docker) à localhost, où Kubernetes peut le trouver sur cette machine. En production réelle, il est probable que le registre Docker sera hébergé sur une machine distincte, afin que tous les noeuds puissent y accéder. “Scaling” de l’application Lors de la deuxième installation de l’ordinateur, j’ai modifié mon déploiement d’origine pour ajouter une autre instance de l’application: Après avoir redémarré le maître et le worker à quelques reprises, la nouvelle instance de mon application a finalement quitté le statut de CreatingContainer et a commencé à s’exécuter: Test de l’équilibrage de charge J’ai utilisé la même procédure pour ouvrir 1000 connexions à Samba s’exécutant sur Kubernetes. Le résultat est intéressant. Master: Worker: Kubernetes / MetalLB a également équilibré la charge sur les deux machines, mais la machine principale a eu un peu moins de connexions que le worker. Je me demande pourquoi. Quoi qu’il en soit, cela montre que j’ai finalement réussi à installer Kubernetes après plusieurs détours. Comparaison et conclusion Fonctionnalités communes aux deux: les deux peuvent gérer des conteneurs et gérer intelligemment les demandes d’équilibrage de charge sur la même application TCP sur deux machines virtuelles différentes. Les deux ont une bonne documentation pour la configuration initiale. Les atouts de Docker Swarm: une configuration simple, aucune configuration requise, une intégration étroite avec Docker. Les points forts de Kubernetes: composants souples, nombreuses ressources disponibles et add-ons. Kubernetes vs Docker Swarm est un compromis entre simplicité et flexibilité. J’ai trouvé plus facile d’installer Docker Swarm, mais je ne peux pas, par exemple, échanger l’équilibreur de charge contre un autre composant. Il n’ya aucun moyen de le configurer: je devrais tout désactiver en même temps. Sur Kubernetes, il m’a fallu un certain temps pour trouver la bonne configuration, mais en échange, je pouvais changer certaines parties de mon cluster selon les besoins et installer facilement des add-ons, tels qu’un tableau de bord sophistiqué. Si vous voulez juste essayer Kubernetes sans toute cette configuration, je vous suggère d’utiliser minikube, qui offre une machine virtuelle de cluster Kubernetes prédéfinie, aucune installation requise. Enfin, je suis impressionné par le fait que les deux moteurs ont pris en charge les services TCP bruts: d’autres fournisseurs de services d’infrastructure en tant que services, tels que Heroku ou Glitch, ne prennent en charge que l’hébergement de sites Web HTTP. La disponibilité des services TCP signifie que l’on peut déployer ses propres serveurs de base de données, ses serveurs de cache et même ses serveurs Minecraft en utilisant les mêmes outils pour déployer des applications Web, faisant de la gestion de l’orchestration de conteneurs une compétence très utile. En conclusion, si je construisais un cluster, j’utiliserais Docker Swarm. Si je payais quelqu’un d’autre pour construire un cluster pour moi, je demanderais Kubernetes. Ce que j’ai appris Comment travailler avec les conteneurs Docker Comment configurer un cluster Docker Swarm à deux noeuds Comment configurer un cluster Kubernetes à deux noeuds et quels choix fonctionneraient pour une application basée sur TCP Comment déployer une application sur Docker Swarm et Kubernetes Comment réparer quoi que ce soit en redémarrant un ordinateur assez souvent, comme si je utilisais encore Windows 98 Kubernetes et Docker Swarm ne sont pas aussi intimidants qu’ils semblent","frontmatter":{"title":"Docker Swarm vs Kubernetes","subtitle":"J'ai trouvé que Docker Swarm est très facile à installer et à configurer, alors que Kubernetes est un peu plus difficile à installer mais reste simple à utiliser."},"fields":{"slug":"/dockerSwarm-vs-kubernetes/"}}},{"node":{"id":"42e1acee-95a7-5a43-8321-5c9d4e0d19ec","timeToRead":8,"excerpt":"Dans Kubernetes, il existe plusieurs façons de publier une application. Il est donc nécessaire de choisir la bonne stratégie pour rendre votre infrastructure fiable lors de la mise à jour d’une application. Le choix de la procédure de déploiement appropriée dépend des besoins. Nous avons énuméré ci-dessous certaines des stratégies possibles à adopter: Recreate RollingUpdate Blue/Green Canary A/B testing Vous pouvez expérimenter chacune de ces stratégies avec Minikube, les manifestes et les étapes à suivre sont expliqués dans ce github Examinons chaque stratégie et voyons quel type d’application vous conviendrez le mieux.  Recreate - idéal pour l’environnement de développement Un déploiement défini avec une stratégie de type recreate mettra fin à toutes les instances en cours d’exécution, puis les recréera avec la version la plus récente.  Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/recreate Avantage État d’application entièrement renouvelé Inconvénients Temps d’arrêt qui dépend à la fois de la durée d’arrêt et du démarrage de l’application  RollingUpdate - déploiement lent Ce déploiement met à jour les pods de façon progressive. Un ReplicaSet secondaire est créé avec la nouvelle version de l’application, puis le nombre de répliques de l’ancienne version est réduit et la nouvelle version est augmentée jusqu’à ce que le nombre correct de répliques soit atteint.  Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/ramped Lors de la configuration avec la mise à l’ échelle automatique du pod horizontal, il peut être pratique d’utiliser une valeur en pourcentage au lieu d’un nombre pour maxSurge et maxUnavailable . maxSurge permet d’indiquez combien de Pod il peut créer en plus du nombre de répliqua actuellement configurer maxUnavailable permet d’indiquer combien de Pod peuvent être “non disponible” pendant la mise à jour, toujours en fonction du nombre de répliqua configuré Si vous déclenchez un déploiement alors qu’un déploiement existant est en cours, le déploiement mettra le déploiement en pause et passera à une nouvelle version en remplaçant le déploiement. Avantages la version est lentement publiée sur toutes les instances pratique pour les applications avec état pouvant gérer le rééquilibrage des données Inconvénients le déploiement/la restauration peut prendre du temps la prise en charge de plusieurs API est difficile aucun contrôle sur le trafic  Blue/Green - mieux éviter les problèmes de versioning de l’API Un déploiement blue/green diffère d’un déploiement parce que la version “green” de l’application est déployée en parallèle de la version “blue”. Après avoir vérifié que la nouvelle version réponde aux exigences, nous mettons à jour l’objet Kubernetes Service qui joue le rôle d’équilibreur de charge pour envoyer du trafic vers la nouvelle version en remplaçant l’étiquette de version dans le champ selector  Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/blue-green Avantages déploiement instantané éviter le problème de versioning, changer l’état du cluster en une fois Inconvénients nécessite le double des ressources le bon test de toute la plate-forme doit être effectué avant la mise en production la gestion des applications avec état peut être difficile  Canary - laissez le consommateur faire le test Le déploiement Canary consiste à router un sous-ensemble d’utilisateurs vers une nouvelle fonctionnalité. Dans Kubernetes, un déploiement canary peut être effectué en utilisant deux déploiements avec des étiquettes de pods communes. Une réplique de la nouvelle version est publiée à côté de l’ancienne version. Ensuite, après un certain temps et si aucune erreur n’est détectée, augmentez le nombre de répliques de la nouvelle version et supprimez l’ancien déploiement. L’utilisation de cette technique ReplicaSet nécessite de faire tourner autant de pod que nécessaire pour obtenir le bon pourcentage de trafic. Cela dit, si vous voulez envoyer 1% du trafic vers la version B, vous devez avoir un pod fonctionnant avec la version B et 99 pods fonctionnant avec la version A. Cela peut être assez peu pratique à gérer donc si vous recherchez une meilleure répartition du trafic, regarder les équilibreurs de charge tels que HAProxy ou les mailles de service comme Linkerd, qui offrent un meilleur contrôle du trafic.  Dans l’exemple suivant, nous utilisons deux ReplicaSets côte à côte, la version A avec trois répliques (75% du trafic), la version B avec un répliqua (25% du trafic). Manifeste de déploiement tronqué version A: Manifeste de déploiement tronqué version B, notez que ous ne démarrons qu’un seul répliqua de l’application: Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/canary Avantages version publiée pour un sous-ensemble d’utilisateurs pratique pour la surveillance du taux d’erreur et des performances rollback rapide Inconvénients déploiement lent la répartition du trafic ajustée peut être coûteuse (99% A / 1% B = 99 pod A, 1 pod B) La procédure utilisée ci-dessus est native de Kubernetes, nous ajustons le nombre de répliques gérées par un ReplicaSet pour distribuer le trafic entre les versions. Si vous n’êtes pas sûr de l’impact que la sortie d’une nouvelle fonctionnalité pourrait avoir sur la stabilité de la plate-forme, une stratégie de sortie canari est suggérée.  A/B testing - idéal pour testes les fonctionnalités sur un sous-ensemble d’utilisateurs Le test A/B est en fait une technique permettant de prendre des décisions d’affaires basées sur des statistiques, plutôt qu’une stratégie de déploiement. Cependant, il est apparenté et peut être mis en oeuvre à l’aide d’un déploiement canari, c’est pourquoi nous en parlerons brièvement ici. En plus de répartir le trafic entre les versions en fonction du poids, vous pouvez cibler précisément un groupe donné d’utilisateurs en fonction de quelques paramètres (cookie, user agent, etc.). Cette technique est largement utilisée pour tester la conversion d’une fonctionnalité donnée et ne déployer que la version qui convient le plus. Istio, comme les autres maillages de service, fournis un moyen plus fin de subdiviser les instances de service avec un routage dynamique des requêtes basé sur des poids et/ou des en-têtes HTTP.  Vous trouverez ci-dessous un exemple d’installation de règles à l’aide d’Istio. Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/ab-testing D’autres outils comme Linkerd, Traefik, NGINX, HAProxy, vous permettent également de le faire. Avantages nécessite un équilibreur de charge intelligent plusieurs versions en parallèle un contrôle total sur la répartition du trafic Inconvénients les erreurs difficiles à dépanner pour une session donnée, le traçage distribué deviennent obligatoires pas simple, vous devez configurer des outils supplémentaires  En résumé Il y a différentes façons de déployer une application, lors de la mise en production dans un environnement de développement/staging, un déploiement big bang ou progressif est généralement un bon choix. Lorsqu’il s’agit de production, un déploiement progressif ou en blue/green est généralement un bon choix, mais un test approprié de la nouvelle plate-forme est nécessaire. Si vous n’êtes pas sûr de la stabilité de la plate-forme et de l’impact que pourrait avoir la sortie d’une nouvelle version de logiciel, alors une version canari devrait être la bonne solution. Ce faisant, vous laissez le consommateur tester l’application et son intégration à la plate-forme. Enfin, si votre entreprise a besoin de tester une nouvelle fonctionnalité parmi un groupe spécifique d’utilisateurs, par exemple, tous les utilisateurs accédant à l’application à l’aide d’un téléphone mobile sont envoyés à la version A, tous les utilisateurs accédant via un ordinateur passent à la version B. Vous pouvez alors utiliser la technique de test A/B qui en utilisant un réseau de services Kubernetes ou une configuration serveur personnalisée vous permet de déterminer où un utilisateur doit être dirigé en fonction de certains paramètres.","frontmatter":{"title":"Stratégie de déploiement de Kubernetes","subtitle":"Dans Kubernetes, il y a plusieurs façons de publier une application, il est nécessaire de choisir la bonne stratégie pour rendre votre infrastructure fiable pendant la mise à jour d'une application."},"fields":{"slug":"/k8s-deployement-strategies/"}}},{"node":{"id":"c6aa09b0-1bea-52f2-9d19-126b12c5cc10","timeToRead":4,"excerpt":"Minikube est un outil idéal pour configuer localement Kubernetes afin de tester et d’expérimenter vos déploiements. Dans ce guide, je vais essayer de vous aider à le mettre en marche sur votre machine locale, à donner quelques conseils sur où et comment effectuer certaines tâches et à le rendre aussi capable (je suppose quand vous utilisez k8s que vous veulent apprendre et utiliser Helm, etcd, istio, etc.). Installation de minikube Minikube fonctionne avec une machine virtuelle. Pour cela, on peut utiliser diverses options en fonction de vos préférences et de votre système d’exploitation. Ma préférence dans ce cas est Orable VirtualBox. Vous pouvez utiliser brew pour tout installer: Dans ce cas, vous pourriez obtenir une erreur d’installation peu concluante liée à l’installation de virtualbox, en particulier sur Mojave et problablement par la suite. Quoi qu’il en soit, il s’agit problablement d’une nouvelle fonctionnalité de sécurité dans MacOs X qui vous gêne. Allez dans Préférences Système> Sécurité et confidentialité et sur l’écran Général, vous verrez un (ou quelques) messages concernant certains logiciels nécessitant une approbation pour être installés. Vous devez examiner attentivement la liste s’il en existe plusieurs et autoriser l’installation du logiciel dont vous avez besoin - dans ce cas, le logiciel Oracle. Cela fait, vous pourrez relancer la commande ci-dessus et vous devrez alors être prêt pour les étapes suivantes. Exécuter et accéder au cluster Afin d’utiliser de manière optimale les ressources de votre ordinateur local, je suggérerais de l’arrêter quand vous n’en avez plus besoin… Avec VirtualBox au centre, il utilisera la batterie de votre ordinateur portable assez rapidement. Recommencer plus tard vous ramènera là où vous l’avez laissé: Le tableau de bord Kubernetes est également disponible (lorsque minikube est en cours d’exécution): Je vais supposer que vous avez kubectl installé localement et que vous l’utilisez déjà pour certains clusters distants, vous disposez donc de plusieurs contextes. Dans ce cas, vous devez répertorier les contextes et passer à minikube. Vous vous trouvez maintenant dans le contexte de votre cluster k8 local qui s’exécute sur minikube et vous pouvez effectuer toutes les opérations k8 qu’il contient. Ingress Pour exécuter vos déploiements comportant un ingress, vous aurez besoin d’un add-on d’entrée: Assurez-vous que vous configurez l’ingress en fonction de vos hôtes locaux. Cela signifie fondamentalement que tout ce que vous définissez comme hôte dans vos règles d’ingress doit être configuré dans votre fichier /etc/hosts Où [minikube ip] devrait être remplacé par l’ip actuel de minikube. Il fonctionne également avec plusieurs hôtes locaux séparés par des espaces après l’adresse ip de minikube. Voici un raccourci pour le faire en bash Docker registry La réalité de l’utilisation réelle du registre de conteneurs dans l’environnement local est rude. Je vais donc vous fournir une option simple, rapide et simpliste qui facilite le déploiement de votre travail local sur vos k8s locaux, mais vous prive de l’expérience très importante du registre de conteneurs. Registre de conteneurs local Obtenez le contexte de votre docker local pour pointer vers le context minikube:  Dans le contexte minikube, pour démarrer le registre docker local Donc, vous avez maintenant un registre local dans lequel pousser des choses (tant que votre docker est dans le contexte minikube) Vous pouvez maintenant faire: A ce stade, vous pouvez utiliser localhost:5000/<your_tag>: comme image dans votre déploiement et c’est tout. Utilisation du référentiel de conteneur distant Pour utiliser localement le référentiel de conteneur distant, vous devez fournir un moyen d’authentification, qui se base sur les secrets de Kubernetes. Pour la gestion des secrets locaux pour ECR, GCR and Docker registry, je recommande d’utiliser l’addon minikube appelé registry-creds. Je ne le considère pas suffisamment sûr pour être utilisé ailleurs que dans l’environnement local. Helm Helm est un gestionnaire de paquets pour k8s et est souvent utilisé pour la gestion de la configuration d’un déploiement à l’autre. Compte tenu de la grande popularité de l’outil et de son adoption croissante, je voudrais terminer ce guide par une note sur l’ajout de helm à votre environnement Kubernetes local. C’est assez facile à ce stade, il suffit de mettre en place minikube et: Helm utilise un backend appelé Tiller. C’est ce qui est installé/déployé lors de l’exécution de helm init. Une lecture précieuse: https://helm.sh/docs/using_helm/ Maintenant, vous disposez d’un environnement Kubernetes local complet capable d’accepter tous vos déploiements de test avant de décider de les placer dans le cloud.","frontmatter":{"title":"Configuration locale de Kubernetes avec minikube sur MacOS X","subtitle":""},"fields":{"slug":"/k8s-minikube/"}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/k8s-minikube/","prev":{"excerpt":"La configuration, le CI et les flux de déploiement représente un peu l’ancien script bash. Malgré mon profond intérêt pour les subtilités de Bash (/sarcasme), j’ai continué à chercher des solution aux mêmes situations sur  Google et StackOverflow. Pour éviter d’avoir à le refaire moi-même et pour votre plaisir de lecture, les voici. Pour être dangereux en termes d’installation, de CI et de flux de déploiement, nous rencontrerons ce qui suit: azerty azerty Vérifier si un fichier existe Vérifier si un lien symbolique existe Vérifier si une variable d’environnement est définie Basculer une variable d’environnement Demander à l’utilisateur Un dernier conseil, s’il s’agit de plusieurs lignes, essayez d’utiliser quelque chose comme JavaScript ou Python pour écrire votre script. Injecter .env dans votre session/environnement Nous avons des fichiers .env, Docker Compose traite cela avec une utilisation habituelle, mais disons que nous voulons que quelque chose tourne en dehors de Docker (et sans utiliser quelque chose comme dotenv). Voici l’extrait de code pour un shell UNIX","timeToRead":2,"frontmatter":{"title":"Bash - Vérifier les variables d'environnement sont définies ou s'il existe des fichiers/références","subtitle":"","tags":["Bash","DevOps"],"category":["Bash","DevOps"],"date":"2019-05-21T22:00:00.000Z","draft":false,"image":{"childImageSharp":{"fluid":{"aspectRatio":1.7777777777777777,"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQBAgMF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAFak9W5wHg//8QAGxAAAQQDAAAAAAAAAAAAAAAAAQACAxESISL/2gAIAQEAAQUCKy6E1BuzHEyqC//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABoQAQACAwEAAAAAAAAAAAAAAAABMRESIYH/2gAIAQEABj8C8Qi3WdVP/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAERITGR/9oACAEBAAE/IaNiOjRsui2rXBjEiRSTh//aAAwDAQACAAMAAAAQpN//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPxBX/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQIBAT8Qp//EABwQAQACAgMBAAAAAAAAAAAAAAEAESFRMUFhwf/aAAgBAQABPxDieh8j0AS9GPIJjMXQwMpryCyIpy61KNPs2wWhNAn/2Q==","sizes":"(max-width: 1600px) 100vw, 1600px","src":"/static/b9929b1a4915b5e4d241ad5af23c0901/989b1/servers.jpg","srcSet":"/static/b9929b1a4915b5e4d241ad5af23c0901/f8f18/servers.jpg 930w,\n/static/b9929b1a4915b5e4d241ad5af23c0901/989b1/servers.jpg 1600w"}}},"author":{"id":"ludo","bio":"Développeur senior. Fullstack + DevOps","avatar":{"children":[{"fixed":{"src":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png"}}]}}},"fields":{"layout":"post","slug":"/bash-justeAssezPourEtreDangereux/"}},"next":{"excerpt":"Dans Kubernetes, il existe plusieurs façons de publier une application. Il est donc nécessaire de choisir la bonne stratégie pour rendre votre infrastructure fiable lors de la mise à jour d’une application. Le choix de la procédure de déploiement appropriée dépend des besoins. Nous avons énuméré ci-dessous certaines des stratégies possibles à adopter: Recreate RollingUpdate Blue/Green Canary A/B testing Vous pouvez expérimenter chacune de ces stratégies avec Minikube, les manifestes et les étapes à suivre sont expliqués dans ce github Examinons chaque stratégie et voyons quel type d’application vous conviendrez le mieux.  Recreate - idéal pour l’environnement de développement Un déploiement défini avec une stratégie de type recreate mettra fin à toutes les instances en cours d’exécution, puis les recréera avec la version la plus récente.  Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/recreate Avantage État d’application entièrement renouvelé Inconvénients Temps d’arrêt qui dépend à la fois de la durée d’arrêt et du démarrage de l’application  RollingUpdate - déploiement lent Ce déploiement met à jour les pods de façon progressive. Un ReplicaSet secondaire est créé avec la nouvelle version de l’application, puis le nombre de répliques de l’ancienne version est réduit et la nouvelle version est augmentée jusqu’à ce que le nombre correct de répliques soit atteint.  Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/ramped Lors de la configuration avec la mise à l’ échelle automatique du pod horizontal, il peut être pratique d’utiliser une valeur en pourcentage au lieu d’un nombre pour maxSurge et maxUnavailable . maxSurge permet d’indiquez combien de Pod il peut créer en plus du nombre de répliqua actuellement configurer maxUnavailable permet d’indiquer combien de Pod peuvent être “non disponible” pendant la mise à jour, toujours en fonction du nombre de répliqua configuré Si vous déclenchez un déploiement alors qu’un déploiement existant est en cours, le déploiement mettra le déploiement en pause et passera à une nouvelle version en remplaçant le déploiement. Avantages la version est lentement publiée sur toutes les instances pratique pour les applications avec état pouvant gérer le rééquilibrage des données Inconvénients le déploiement/la restauration peut prendre du temps la prise en charge de plusieurs API est difficile aucun contrôle sur le trafic  Blue/Green - mieux éviter les problèmes de versioning de l’API Un déploiement blue/green diffère d’un déploiement parce que la version “green” de l’application est déployée en parallèle de la version “blue”. Après avoir vérifié que la nouvelle version réponde aux exigences, nous mettons à jour l’objet Kubernetes Service qui joue le rôle d’équilibreur de charge pour envoyer du trafic vers la nouvelle version en remplaçant l’étiquette de version dans le champ selector  Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/blue-green Avantages déploiement instantané éviter le problème de versioning, changer l’état du cluster en une fois Inconvénients nécessite le double des ressources le bon test de toute la plate-forme doit être effectué avant la mise en production la gestion des applications avec état peut être difficile  Canary - laissez le consommateur faire le test Le déploiement Canary consiste à router un sous-ensemble d’utilisateurs vers une nouvelle fonctionnalité. Dans Kubernetes, un déploiement canary peut être effectué en utilisant deux déploiements avec des étiquettes de pods communes. Une réplique de la nouvelle version est publiée à côté de l’ancienne version. Ensuite, après un certain temps et si aucune erreur n’est détectée, augmentez le nombre de répliques de la nouvelle version et supprimez l’ancien déploiement. L’utilisation de cette technique ReplicaSet nécessite de faire tourner autant de pod que nécessaire pour obtenir le bon pourcentage de trafic. Cela dit, si vous voulez envoyer 1% du trafic vers la version B, vous devez avoir un pod fonctionnant avec la version B et 99 pods fonctionnant avec la version A. Cela peut être assez peu pratique à gérer donc si vous recherchez une meilleure répartition du trafic, regarder les équilibreurs de charge tels que HAProxy ou les mailles de service comme Linkerd, qui offrent un meilleur contrôle du trafic.  Dans l’exemple suivant, nous utilisons deux ReplicaSets côte à côte, la version A avec trois répliques (75% du trafic), la version B avec un répliqua (25% du trafic). Manifeste de déploiement tronqué version A: Manifeste de déploiement tronqué version B, notez que ous ne démarrons qu’un seul répliqua de l’application: Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/canary Avantages version publiée pour un sous-ensemble d’utilisateurs pratique pour la surveillance du taux d’erreur et des performances rollback rapide Inconvénients déploiement lent la répartition du trafic ajustée peut être coûteuse (99% A / 1% B = 99 pod A, 1 pod B) La procédure utilisée ci-dessus est native de Kubernetes, nous ajustons le nombre de répliques gérées par un ReplicaSet pour distribuer le trafic entre les versions. Si vous n’êtes pas sûr de l’impact que la sortie d’une nouvelle fonctionnalité pourrait avoir sur la stabilité de la plate-forme, une stratégie de sortie canari est suggérée.  A/B testing - idéal pour testes les fonctionnalités sur un sous-ensemble d’utilisateurs Le test A/B est en fait une technique permettant de prendre des décisions d’affaires basées sur des statistiques, plutôt qu’une stratégie de déploiement. Cependant, il est apparenté et peut être mis en oeuvre à l’aide d’un déploiement canari, c’est pourquoi nous en parlerons brièvement ici. En plus de répartir le trafic entre les versions en fonction du poids, vous pouvez cibler précisément un groupe donné d’utilisateurs en fonction de quelques paramètres (cookie, user agent, etc.). Cette technique est largement utilisée pour tester la conversion d’une fonctionnalité donnée et ne déployer que la version qui convient le plus. Istio, comme les autres maillages de service, fournis un moyen plus fin de subdiviser les instances de service avec un routage dynamique des requêtes basé sur des poids et/ou des en-têtes HTTP.  Vous trouverez ci-dessous un exemple d’installation de règles à l’aide d’Istio. Vous trouverez un exemple complet et les étapes de déploiement à l’adresse https://github.com/ludovicwyffels/k8s-deployment-demo/tree/master/ab-testing D’autres outils comme Linkerd, Traefik, NGINX, HAProxy, vous permettent également de le faire. Avantages nécessite un équilibreur de charge intelligent plusieurs versions en parallèle un contrôle total sur la répartition du trafic Inconvénients les erreurs difficiles à dépanner pour une session donnée, le traçage distribué deviennent obligatoires pas simple, vous devez configurer des outils supplémentaires  En résumé Il y a différentes façons de déployer une application, lors de la mise en production dans un environnement de développement/staging, un déploiement big bang ou progressif est généralement un bon choix. Lorsqu’il s’agit de production, un déploiement progressif ou en blue/green est généralement un bon choix, mais un test approprié de la nouvelle plate-forme est nécessaire. Si vous n’êtes pas sûr de la stabilité de la plate-forme et de l’impact que pourrait avoir la sortie d’une nouvelle version de logiciel, alors une version canari devrait être la bonne solution. Ce faisant, vous laissez le consommateur tester l’application et son intégration à la plate-forme. Enfin, si votre entreprise a besoin de tester une nouvelle fonctionnalité parmi un groupe spécifique d’utilisateurs, par exemple, tous les utilisateurs accédant à l’application à l’aide d’un téléphone mobile sont envoyés à la version A, tous les utilisateurs accédant via un ordinateur passent à la version B. Vous pouvez alors utiliser la technique de test A/B qui en utilisant un réseau de services Kubernetes ou une configuration serveur personnalisée vous permet de déterminer où un utilisateur doit être dirigé en fonction de certains paramètres.","timeToRead":8,"frontmatter":{"title":"Stratégie de déploiement de Kubernetes","subtitle":"Dans Kubernetes, il y a plusieurs façons de publier une application, il est nécessaire de choisir la bonne stratégie pour rendre votre infrastructure fiable pendant la mise à jour d'une application.","tags":["Kubernetes","DevOps"],"category":["DevOps"],"date":"2019-05-25T08:00:00.000Z","draft":false,"image":{"childImageSharp":{"fluid":{"aspectRatio":1.33422281521014,"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgT/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAABzC2jBYj/xAAaEAACAgMAAAAAAAAAAAAAAAABAgARITFC/9oACAEBAAEFAu8hQtzZANss/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQIBAT8BR//EABkQAAMAAwAAAAAAAAAAAAAAAAABERAxQf/aAAgBAQAGPwJXREcEs//EABgQAQEBAQEAAAAAAAAAAAAAAAERADFh/9oACAEBAAE/IRsrGWEVe4jVD66plnHI7Z2ZqM6Xf//aAAwDAQACAAMAAAAQwP8A/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERMf/aAAgBAwEBPxDZU//EABcRAAMBAAAAAAAAAAAAAAAAAAABESH/2gAIAQIBAT8QxIg//8QAHhABAAICAgMBAAAAAAAAAAAAAQAhEUExYXGBkaH/2gAIAQEAAT8QZGFr56O45sQgzWiXtrCEP6wYQCWcsZ1Hgda+xT8AxY17n//Z","sizes":"(max-width: 2000px) 100vw, 2000px","src":"/static/cc32bd959fba19866af4a1302ca23593/883ab/interchange.jpg","srcSet":"/static/cc32bd959fba19866af4a1302ca23593/f8f18/interchange.jpg 930w,\n/static/cc32bd959fba19866af4a1302ca23593/0e6ff/interchange.jpg 1860w,\n/static/cc32bd959fba19866af4a1302ca23593/883ab/interchange.jpg 2000w"}}},"author":{"id":"ludo","bio":"Développeur senior. Fullstack + DevOps","avatar":{"children":[{"fixed":{"src":"/static/5f2c129e42248a92c87b13b4293950cf/4e842/ghost.png"}}]}}},"fields":{"layout":"post","slug":"/k8s-deployement-strategies/"}},"primaryTag":"Kubernetes","primaryCategory":"Kubernetes"}}}